{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/credit/application_record.csv')\n",
    "\n",
    "record = pd.read_csv('data/credit/credit_record.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (438557, 18)\n",
      "Index(['ID', 'CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY', 'CNT_CHILDREN',\n",
      "       'AMT_INCOME_TOTAL', 'NAME_INCOME_TYPE', 'NAME_EDUCATION_TYPE',\n",
      "       'NAME_FAMILY_STATUS', 'NAME_HOUSING_TYPE', 'DAYS_BIRTH',\n",
      "       'DAYS_EMPLOYED', 'FLAG_MOBIL', 'FLAG_WORK_PHONE', 'FLAG_PHONE',\n",
      "       'FLAG_EMAIL', 'OCCUPATION_TYPE', 'CNT_FAM_MEMBERS'],\n",
      "      dtype='object')\n",
      "Shape: (1048575, 3)\n",
      "Index(['ID', 'MONTHS_BALANCE', 'STATUS'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape: {data.shape}\")\n",
    "print(data.columns)\n",
    "print(f\"Shape: {record.shape}\")\n",
    "print(record.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaggle Notebook: https://www.kaggle.com/code/rikdifos/credit-card-approval-prediction-using-ml/notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Target variable**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 0: 1-29 days past due \n",
    "- 1: 30-59 days past due \n",
    "- 2: 60-89 days overdue \n",
    "- 3: 90-119 days overdue \n",
    "- 4: 120-149 days overdue \n",
    "- 5: Overdue or bad debts, write-offs for more than 150 days \n",
    "- C: paid off that month \n",
    "- X: No loan for the month\n",
    "\n",
    "\n",
    "TARGET VARIABLE: User at risk (1/0). 1 if overdue for more than 60 days (label 2,3,4,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STATUS\n",
       "C    442031\n",
       "0    383120\n",
       "X    209230\n",
       "1     11090\n",
       "5      1693\n",
       "2       868\n",
       "3       320\n",
       "4       223\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record.STATUS.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\giorg\\AppData\\Local\\Temp\\ipykernel_54148\\1215647021.py:2: FutureWarning: The provided callable <built-in function min> is currently using SeriesGroupBy.min. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"min\" instead.\n",
      "  begin_month = pd.DataFrame(record.groupby([\"ID\"])[\"MONTHS_BALANCE\"].agg(min))\n"
     ]
    }
   ],
   "source": [
    "# Create variable \"begin_month\" --> age of the account\n",
    "begin_month = pd.DataFrame(record.groupby([\"ID\"])[\"MONTHS_BALANCE\"].agg(min))\n",
    "begin_month = begin_month.rename(columns={'MONTHS_BALANCE':'begin_month'}) \n",
    "\n",
    "new_data = pd.merge(data,begin_month,how=\"left\",on=\"ID\") #merge to record data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    35841\n",
       "1      616\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record['dep_value'] = np.where(record['STATUS'].isin(['2','3','4','5']), 'Yes', None)\n",
    "\n",
    "# Flag customers who have been late 60+ days at least once\n",
    "cpunt = record.groupby('ID').count()\n",
    "cpunt['dep_value'] = np.where(cpunt['dep_value'] >0, 'Yes','No')\n",
    "cpunt = cpunt[['dep_value']]\n",
    "\n",
    "new_data = pd.merge(new_data, cpunt, how='inner', on='ID')\n",
    "\n",
    "new_data['target'] = new_data['dep_value']\n",
    "new_data['target'] = np.where(new_data['target']=='Yes', 1, 0)\n",
    "\n",
    "new_data.target.value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binary Variables\n",
    "\n",
    "**Gender**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CODE_GENDER\n",
      "F    24430\n",
      "M    12027\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(new_data['CODE_GENDER'].value_counts())\n",
    "\n",
    "new_data['CODE_GENDER'] = np.where(new_data['CODE_GENDER']=='M', 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data['CODE_GENDER'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Own a car**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FLAG_OWN_CAR\n",
      "N    22614\n",
      "Y    13843\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(new_data['FLAG_OWN_CAR'].value_counts())\n",
    "\n",
    "new_data['FLAG_OWN_CAR'] = np.where(new_data['FLAG_OWN_CAR']=='Y', 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Own Realty**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FLAG_OWN_REALTY\n",
      "Y    24506\n",
      "N    11951\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(new_data['FLAG_OWN_REALTY'].value_counts())\n",
    "\n",
    "new_data['FLAG_OWN_REALTY'] = np.where(new_data['FLAG_OWN_REALTY']=='Y', 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Own Phone**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FLAG_PHONE\n",
      "0    25709\n",
      "1    10748\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(new_data['FLAG_PHONE'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Own Work Phone**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['FLAG_WORK_PHONE'] = np.where(new_data['FLAG_WORK_PHONE']=='Y', 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Own Email**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FLAG_EMAIL\n",
       "0    33186\n",
       "1     3271\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data['FLAG_EMAIL'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numerical Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Children Count**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNT_CHILDREN\n",
       "0     25201\n",
       "1      7492\n",
       "2      3256\n",
       "3       419\n",
       "4        63\n",
       "5        20\n",
       "14        3\n",
       "7         2\n",
       "19        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data['CNT_CHILDREN'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNT_CHILDREN\n",
      "0               25201\n",
      "1                7492\n",
      "2+ childrens     3764\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "new_data['CNT_CHILDREN'] = np.where(new_data['CNT_CHILDREN']>=2, '2+ childrens',\n",
    "                                    np.where(new_data['CNT_CHILDREN']==1, '1', '0'))\n",
    "\n",
    "print(new_data['CNT_CHILDREN'].value_counts())\n",
    "new_data = pd.get_dummies(new_data, columns=['CNT_CHILDREN'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Income**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3.645700e+04\n",
       "mean     1.866857e+05\n",
       "std      1.017892e+05\n",
       "min      2.700000e+04\n",
       "25%      1.215000e+05\n",
       "50%      1.575000e+05\n",
       "75%      2.250000e+05\n",
       "max      1.575000e+06\n",
       "Name: AMT_INCOME_TOTAL, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data['AMT_INCOME_TOTAL'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['AMT_INCOME_TOTAL'] = new_data['AMT_INCOME_TOTAL']/10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AMT_INCOME_TOTAL\n",
       "low       14473\n",
       "high      11282\n",
       "medium    10702\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data['AMT_INCOME_TOTAL'] = pd.qcut(new_data['AMT_INCOME_TOTAL'], q = 3, labels = [\"low\",\"medium\", \"high\"])\n",
    "new_data['AMT_INCOME_TOTAL'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.get_dummies(new_data, columns=['AMT_INCOME_TOTAL'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Age**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['AGE'] = new_data['DAYS_BIRTH']/-365\n",
    "\n",
    "new_data['AGE'] = pd.qcut(new_data['AGE'], q = 3, labels = [\"low\",\"medium\", \"high\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AGE\n",
       "low       12156\n",
       "high      12152\n",
       "medium    12149\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data['AGE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.get_dummies(new_data, columns=['AGE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Working Years**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YEARS_EMPLOYED\n",
       "low        6083\n",
       "lowest     6072\n",
       "highest    6065\n",
       "high       6063\n",
       "medium     6039\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data['YEARS_EMPLOYED'] = - new_data['DAYS_EMPLOYED'] / 365\t\n",
    "new_data['YEARS_EMPLOYED'] = np.where(new_data['YEARS_EMPLOYED']<0, np.nan,new_data['YEARS_EMPLOYED'])\n",
    "\n",
    "new_data['YEARS_EMPLOYED'] = pd.qcut(new_data['YEARS_EMPLOYED'], q = 5, labels = [\"lowest\",\"low\",\"medium\",\"high\",\"highest\"])\n",
    "new_data['YEARS_EMPLOYED'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.get_dummies(new_data, columns=['YEARS_EMPLOYED'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Family Size**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNT_FAM_MEMBERS\n",
       "2.0     19463\n",
       "1.0      6987\n",
       "3.0      6421\n",
       "4.0      3106\n",
       "5.0       397\n",
       "6.0        58\n",
       "7.0        19\n",
       "15.0        3\n",
       "9.0         2\n",
       "20.0        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data['CNT_FAM_MEMBERS'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['CNT_FAM_MEMBERS'] = np.where(new_data['CNT_FAM_MEMBERS']>=3, '3+ members', \n",
    "                                       np.where(new_data['CNT_FAM_MEMBERS']==2, '2',\n",
    "                                                np.where(new_data['CNT_FAM_MEMBERS']==1, '1', '0')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.get_dummies(new_data, columns=['CNT_FAM_MEMBERS'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical Variables\n",
    "\n",
    "**Occupation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the occupation categories\n",
    "laborwk_categories = ['Cleaning staff', 'Cooking staff', 'Drivers', 'Laborers', 'Low-skill Laborers', 'Security staff', 'Waiters/barmen staff']\n",
    "officewk_categories = ['Accountants', 'Core staff', 'HR staff', 'Medicine staff', 'Private service staff', 'Realty agents', 'Sales staff', 'Secretaries']\n",
    "hightecwk_categories = ['Managers', 'High skill tech staff', 'IT staff']\n",
    "\n",
    "new_data['OCCUPATION_TYPE'] = np.where(new_data['OCCUPATION_TYPE'].isin(laborwk_categories), 'labor', \n",
    "                                       np.where(new_data['OCCUPATION_TYPE'].isin(officewk_categories), 'office',\n",
    "                                                np.where(new_data['OCCUPATION_TYPE'].isin(hightecwk_categories), 'hightec', 'other')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OCCUPATION_TYPE\n",
       "other      11323\n",
       "labor      10496\n",
       "office     10183\n",
       "hightec     4455\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.OCCUPATION_TYPE.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.get_dummies(new_data, columns=['OCCUPATION_TYPE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Income**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['NAME_INCOME_TYPE'] = np.where(new_data['NAME_INCOME_TYPE'].isin(['Pensioner', 'Student']), 'State servant' ,new_data['NAME_INCOME_TYPE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NAME_INCOME_TYPE\n",
       "Working                 18819\n",
       "State servant            9148\n",
       "Commercial associate     8490\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.NAME_INCOME_TYPE.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create dummy variables - one hot encoding\n",
    "new_data = pd.get_dummies(new_data, columns=['NAME_INCOME_TYPE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**House Type**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NAME_HOUSING_TYPE\n",
       "House / apartment      32548\n",
       "With parents            1776\n",
       "Municipal apartment     1128\n",
       "Rented apartment         575\n",
       "Office apartment         262\n",
       "Co-op apartment          168\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data['NAME_HOUSING_TYPE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.get_dummies(new_data, columns=['NAME_HOUSING_TYPE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Acedemic level**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NAME_EDUCATION_TYPE\n",
       "Secondary / secondary special    24777\n",
       "Higher education                  9864\n",
       "Incomplete higher                 1410\n",
       "Lower secondary                    374\n",
       "Academic degree                     32\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data['NAME_EDUCATION_TYPE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['NAME_EDUCATION_TYPE'] = np.where(new_data['NAME_EDUCATION_TYPE']=='Academic degree', 'Higher education', new_data['NAME_EDUCATION_TYPE'])\n",
    "\n",
    "# dummies\n",
    "new_data = pd.get_dummies(new_data, columns=['NAME_EDUCATION_TYPE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Marriage Condition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NAME_FAMILY_STATUS\n",
       "Married                 25048\n",
       "Single / not married     4829\n",
       "Civil marriage           2945\n",
       "Separated                2103\n",
       "Widow                    1532\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data['NAME_FAMILY_STATUS'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.get_dummies(new_data, columns=['NAME_FAMILY_STATUS'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY', 'DAYS_BIRTH',\n",
       "       'DAYS_EMPLOYED', 'FLAG_MOBIL', 'FLAG_WORK_PHONE', 'FLAG_PHONE',\n",
       "       'FLAG_EMAIL', 'begin_month', 'dep_value', 'target', 'CNT_CHILDREN_0',\n",
       "       'CNT_CHILDREN_1', 'CNT_CHILDREN_2+ childrens', 'AMT_INCOME_TOTAL_low',\n",
       "       'AMT_INCOME_TOTAL_medium', 'AMT_INCOME_TOTAL_high', 'AGE_low',\n",
       "       'AGE_medium', 'AGE_high', 'YEARS_EMPLOYED_lowest', 'YEARS_EMPLOYED_low',\n",
       "       'YEARS_EMPLOYED_medium', 'YEARS_EMPLOYED_high',\n",
       "       'YEARS_EMPLOYED_highest', 'CNT_FAM_MEMBERS_1', 'CNT_FAM_MEMBERS_2',\n",
       "       'CNT_FAM_MEMBERS_3+ members', 'OCCUPATION_TYPE_hightec',\n",
       "       'OCCUPATION_TYPE_labor', 'OCCUPATION_TYPE_office',\n",
       "       'OCCUPATION_TYPE_other', 'NAME_INCOME_TYPE_Commercial associate',\n",
       "       'NAME_INCOME_TYPE_State servant', 'NAME_INCOME_TYPE_Working',\n",
       "       'NAME_HOUSING_TYPE_Co-op apartment',\n",
       "       'NAME_HOUSING_TYPE_House / apartment',\n",
       "       'NAME_HOUSING_TYPE_Municipal apartment',\n",
       "       'NAME_HOUSING_TYPE_Office apartment',\n",
       "       'NAME_HOUSING_TYPE_Rented apartment', 'NAME_HOUSING_TYPE_With parents',\n",
       "       'NAME_EDUCATION_TYPE_Higher education',\n",
       "       'NAME_EDUCATION_TYPE_Incomplete higher',\n",
       "       'NAME_EDUCATION_TYPE_Lower secondary',\n",
       "       'NAME_EDUCATION_TYPE_Secondary / secondary special',\n",
       "       'NAME_FAMILY_STATUS_Civil marriage', 'NAME_FAMILY_STATUS_Married',\n",
       "       'NAME_FAMILY_STATUS_Separated',\n",
       "       'NAME_FAMILY_STATUS_Single / not married', 'NAME_FAMILY_STATUS_Widow'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new_data.drop(['ID','target','dep_value'], axis=1)\n",
    "y = new_data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "DLL load failed while importing _argkmin: The filename or extension is too long.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\giorg\\OneDrive\\Desktop\\G\\Education\\Master\\Academics\\Courses\\15095 Machine Learning Under a Modern Optimization Lens\\Project\\TabText-Experiments\\Giorgio_baseline.ipynb Cell 64\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/giorg/OneDrive/Desktop/G/Education/Master/Academics/Courses/15095%20Machine%20Learning%20Under%20a%20Modern%20Optimization%20Lens/Project/TabText-Experiments/Giorgio_baseline.ipynb#Y253sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m train_test_split\n",
      "File \u001b[1;32mc:\\Users\\giorg\\OneDrive\\Desktop\\G\\Education\\Master\\Academics\\Courses\\15095 Machine Learning Under a Modern Optimization Lens\\Project\\TabText-Experiments\\MLVenv\\lib\\site-packages\\sklearn\\model_selection\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtyping\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_plot\u001b[39;00m \u001b[39mimport\u001b[39;00m LearningCurveDisplay, ValidationCurveDisplay\n\u001b[0;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_search\u001b[39;00m \u001b[39mimport\u001b[39;00m GridSearchCV, ParameterGrid, ParameterSampler, RandomizedSearchCV\n\u001b[0;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_split\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m      6\u001b[0m     BaseCrossValidator,\n\u001b[0;32m      7\u001b[0m     BaseShuffleSplit,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     24\u001b[0m     train_test_split,\n\u001b[0;32m     25\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\giorg\\OneDrive\\Desktop\\G\\Education\\Master\\Academics\\Courses\\15095 Machine Learning Under a Modern Optimization Lens\\Project\\TabText-Experiments\\MLVenv\\lib\\site-packages\\sklearn\\model_selection\\_plot.py:7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m check_matplotlib_support\n\u001b[0;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_plotting\u001b[39;00m \u001b[39mimport\u001b[39;00m _interval_max_min_ratio, _validate_score_name\n\u001b[1;32m----> 7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_validation\u001b[39;00m \u001b[39mimport\u001b[39;00m learning_curve, validation_curve\n\u001b[0;32m     10\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39m_BaseCurveDisplay\u001b[39;00m:\n\u001b[0;32m     11\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m_plot_curve\u001b[39m(\n\u001b[0;32m     12\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[0;32m     13\u001b[0m         x_data,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     23\u001b[0m         errorbar_kw\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m     24\u001b[0m     ):\n",
      "File \u001b[1;32mc:\\Users\\giorg\\OneDrive\\Desktop\\G\\Education\\Master\\Academics\\Courses\\15095 Machine Learning Under a Modern Optimization Lens\\Project\\TabText-Experiments\\MLVenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:29\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbase\u001b[39;00m \u001b[39mimport\u001b[39;00m clone, is_classifier\n\u001b[0;32m     28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexceptions\u001b[39;00m \u001b[39mimport\u001b[39;00m FitFailedWarning\n\u001b[1;32m---> 29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m check_scoring, get_scorer_names\n\u001b[0;32m     30\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_scorer\u001b[39;00m \u001b[39mimport\u001b[39;00m _check_multimetric_scoring, _MultimetricScorer\n\u001b[0;32m     31\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m \u001b[39mimport\u001b[39;00m LabelEncoder\n",
      "File \u001b[1;32mc:\\Users\\giorg\\OneDrive\\Desktop\\G\\Education\\Master\\Academics\\Courses\\15095 Machine Learning Under a Modern Optimization Lens\\Project\\TabText-Experiments\\MLVenv\\lib\\site-packages\\sklearn\\metrics\\__init__.py:7\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mThe :mod:`sklearn.metrics` module includes score functions, performance metrics\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39mand pairwise metrics and distance computations.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m cluster\n\u001b[0;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_classification\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m      9\u001b[0m     accuracy_score,\n\u001b[0;32m     10\u001b[0m     balanced_accuracy_score,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     27\u001b[0m     zero_one_loss,\n\u001b[0;32m     28\u001b[0m )\n\u001b[0;32m     29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_dist_metrics\u001b[39;00m \u001b[39mimport\u001b[39;00m DistanceMetric\n",
      "File \u001b[1;32mc:\\Users\\giorg\\OneDrive\\Desktop\\G\\Education\\Master\\Academics\\Courses\\15095 Machine Learning Under a Modern Optimization Lens\\Project\\TabText-Experiments\\MLVenv\\lib\\site-packages\\sklearn\\metrics\\cluster\\__init__.py:25\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_bicluster\u001b[39;00m \u001b[39mimport\u001b[39;00m consensus_score\n\u001b[0;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_supervised\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     10\u001b[0m     adjusted_mutual_info_score,\n\u001b[0;32m     11\u001b[0m     adjusted_rand_score,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     23\u001b[0m     v_measure_score,\n\u001b[0;32m     24\u001b[0m )\n\u001b[1;32m---> 25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_unsupervised\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     26\u001b[0m     calinski_harabasz_score,\n\u001b[0;32m     27\u001b[0m     davies_bouldin_score,\n\u001b[0;32m     28\u001b[0m     silhouette_samples,\n\u001b[0;32m     29\u001b[0m     silhouette_score,\n\u001b[0;32m     30\u001b[0m )\n\u001b[0;32m     32\u001b[0m __all__ \u001b[39m=\u001b[39m [\n\u001b[0;32m     33\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39madjusted_mutual_info_score\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     34\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mnormalized_mutual_info_score\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mconsensus_score\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     52\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\giorg\\OneDrive\\Desktop\\G\\Education\\Master\\Academics\\Courses\\15095 Machine Learning Under a Modern Optimization Lens\\Project\\TabText-Experiments\\MLVenv\\lib\\site-packages\\sklearn\\metrics\\cluster\\_unsupervised.py:22\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m _safe_indexing, check_random_state, check_X_y\n\u001b[0;32m     17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_param_validation\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     18\u001b[0m     Interval,\n\u001b[0;32m     19\u001b[0m     StrOptions,\n\u001b[0;32m     20\u001b[0m     validate_params,\n\u001b[0;32m     21\u001b[0m )\n\u001b[1;32m---> 22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpairwise\u001b[39;00m \u001b[39mimport\u001b[39;00m _VALID_METRICS, pairwise_distances, pairwise_distances_chunked\n\u001b[0;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcheck_number_of_labels\u001b[39m(n_labels, n_samples):\n\u001b[0;32m     26\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Check that number of labels are valid.\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \n\u001b[0;32m     28\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[39m        Number of samples.\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\giorg\\OneDrive\\Desktop\\G\\Education\\Master\\Academics\\Courses\\15095 Machine Learning Under a Modern Optimization Lens\\Project\\TabText-Experiments\\MLVenv\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:44\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mparallel\u001b[39;00m \u001b[39mimport\u001b[39;00m Parallel, delayed\n\u001b[0;32m     43\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mvalidation\u001b[39;00m \u001b[39mimport\u001b[39;00m _num_samples, check_non_negative\n\u001b[1;32m---> 44\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_pairwise_distances_reduction\u001b[39;00m \u001b[39mimport\u001b[39;00m ArgKmin\n\u001b[0;32m     45\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_pairwise_fast\u001b[39;00m \u001b[39mimport\u001b[39;00m _chi2_kernel_fast, _sparse_manhattan\n\u001b[0;32m     48\u001b[0m \u001b[39m# Utility Functions\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\giorg\\OneDrive\\Desktop\\G\\Education\\Master\\Academics\\Courses\\15095 Machine Learning Under a Modern Optimization Lens\\Project\\TabText-Experiments\\MLVenv\\lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\__init__.py:89\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Pairwise Distances Reductions\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m# =============================\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[39m#    using Generalized Matrix Multiplication over `float64` data (see the\u001b[39;00m\n\u001b[0;32m     86\u001b[0m \u001b[39m#    docstring of :class:`GEMMTermComputer64` for details).\u001b[39;00m\n\u001b[1;32m---> 89\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_dispatcher\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     90\u001b[0m     ArgKmin,\n\u001b[0;32m     91\u001b[0m     ArgKminClassMode,\n\u001b[0;32m     92\u001b[0m     BaseDistancesReductionDispatcher,\n\u001b[0;32m     93\u001b[0m     RadiusNeighbors,\n\u001b[0;32m     94\u001b[0m     sqeuclidean_row_norms,\n\u001b[0;32m     95\u001b[0m )\n\u001b[0;32m     97\u001b[0m __all__ \u001b[39m=\u001b[39m [\n\u001b[0;32m     98\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mBaseDistancesReductionDispatcher\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     99\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mArgKmin\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39msqeuclidean_row_norms\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    103\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\giorg\\OneDrive\\Desktop\\G\\Education\\Master\\Academics\\Courses\\15095 Machine Learning Under a Modern Optimization Lens\\Project\\TabText-Experiments\\MLVenv\\lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py:9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m get_config\n\u001b[0;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_dist_metrics\u001b[39;00m \u001b[39mimport\u001b[39;00m BOOL_METRICS, METRIC_MAPPING64\n\u001b[1;32m----> 9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_argkmin\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     10\u001b[0m     ArgKmin32,\n\u001b[0;32m     11\u001b[0m     ArgKmin64,\n\u001b[0;32m     12\u001b[0m )\n\u001b[0;32m     13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_argkmin_classmode\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     14\u001b[0m     ArgKminClassMode32,\n\u001b[0;32m     15\u001b[0m     ArgKminClassMode64,\n\u001b[0;32m     16\u001b[0m )\n\u001b[0;32m     17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_base\u001b[39;00m \u001b[39mimport\u001b[39;00m _sqeuclidean_row_norms32, _sqeuclidean_row_norms64\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing _argkmin: The filename or extension is too long."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, \n",
    "                                                    stratify=y, test_size=0.3,\n",
    "                                                    random_state = 10086)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "DLL load failed while importing _argkmin: The filename or extension is too long.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\giorg\\OneDrive\\Desktop\\G\\Education\\Master\\Academics\\Courses\\15095 Machine Learning Under a Modern Optimization Lens\\Project\\TabText-Experiments\\Giorgio_baseline.ipynb Cell 67\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/giorg/OneDrive/Desktop/G/Education/Master/Academics/Courses/15095%20Machine%20Learning%20Under%20a%20Modern%20Optimization%20Lens/Project/TabText-Experiments/Giorgio_baseline.ipynb#Y303sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m accuracy_score, confusion_matrix, plot_confusion_matrix\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/giorg/OneDrive/Desktop/G/Education/Master/Academics/Courses/15095%20Machine%20Learning%20Under%20a%20Modern%20Optimization%20Lens/Project/TabText-Experiments/Giorgio_baseline.ipynb#Y303sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlinear_model\u001b[39;00m \u001b[39mimport\u001b[39;00m LogisticRegression\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/giorg/OneDrive/Desktop/G/Education/Master/Academics/Courses/15095%20Machine%20Learning%20Under%20a%20Modern%20Optimization%20Lens/Project/TabText-Experiments/Giorgio_baseline.ipynb#Y303sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mseaborn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39msns\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\giorg\\OneDrive\\Desktop\\G\\Education\\Master\\Academics\\Courses\\15095 Machine Learning Under a Modern Optimization Lens\\Project\\TabText-Experiments\\MLVenv\\lib\\site-packages\\sklearn\\metrics\\__init__.py:7\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mThe :mod:`sklearn.metrics` module includes score functions, performance metrics\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39mand pairwise metrics and distance computations.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m cluster\n\u001b[0;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_classification\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m      9\u001b[0m     accuracy_score,\n\u001b[0;32m     10\u001b[0m     balanced_accuracy_score,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     27\u001b[0m     zero_one_loss,\n\u001b[0;32m     28\u001b[0m )\n\u001b[0;32m     29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_dist_metrics\u001b[39;00m \u001b[39mimport\u001b[39;00m DistanceMetric\n",
      "File \u001b[1;32mc:\\Users\\giorg\\OneDrive\\Desktop\\G\\Education\\Master\\Academics\\Courses\\15095 Machine Learning Under a Modern Optimization Lens\\Project\\TabText-Experiments\\MLVenv\\lib\\site-packages\\sklearn\\metrics\\cluster\\__init__.py:25\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_bicluster\u001b[39;00m \u001b[39mimport\u001b[39;00m consensus_score\n\u001b[0;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_supervised\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     10\u001b[0m     adjusted_mutual_info_score,\n\u001b[0;32m     11\u001b[0m     adjusted_rand_score,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     23\u001b[0m     v_measure_score,\n\u001b[0;32m     24\u001b[0m )\n\u001b[1;32m---> 25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_unsupervised\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     26\u001b[0m     calinski_harabasz_score,\n\u001b[0;32m     27\u001b[0m     davies_bouldin_score,\n\u001b[0;32m     28\u001b[0m     silhouette_samples,\n\u001b[0;32m     29\u001b[0m     silhouette_score,\n\u001b[0;32m     30\u001b[0m )\n\u001b[0;32m     32\u001b[0m __all__ \u001b[39m=\u001b[39m [\n\u001b[0;32m     33\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39madjusted_mutual_info_score\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     34\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mnormalized_mutual_info_score\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mconsensus_score\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     52\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\giorg\\OneDrive\\Desktop\\G\\Education\\Master\\Academics\\Courses\\15095 Machine Learning Under a Modern Optimization Lens\\Project\\TabText-Experiments\\MLVenv\\lib\\site-packages\\sklearn\\metrics\\cluster\\_unsupervised.py:22\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m _safe_indexing, check_random_state, check_X_y\n\u001b[0;32m     17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_param_validation\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     18\u001b[0m     Interval,\n\u001b[0;32m     19\u001b[0m     StrOptions,\n\u001b[0;32m     20\u001b[0m     validate_params,\n\u001b[0;32m     21\u001b[0m )\n\u001b[1;32m---> 22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpairwise\u001b[39;00m \u001b[39mimport\u001b[39;00m _VALID_METRICS, pairwise_distances, pairwise_distances_chunked\n\u001b[0;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcheck_number_of_labels\u001b[39m(n_labels, n_samples):\n\u001b[0;32m     26\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Check that number of labels are valid.\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \n\u001b[0;32m     28\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[39m        Number of samples.\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\giorg\\OneDrive\\Desktop\\G\\Education\\Master\\Academics\\Courses\\15095 Machine Learning Under a Modern Optimization Lens\\Project\\TabText-Experiments\\MLVenv\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:44\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mparallel\u001b[39;00m \u001b[39mimport\u001b[39;00m Parallel, delayed\n\u001b[0;32m     43\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mvalidation\u001b[39;00m \u001b[39mimport\u001b[39;00m _num_samples, check_non_negative\n\u001b[1;32m---> 44\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_pairwise_distances_reduction\u001b[39;00m \u001b[39mimport\u001b[39;00m ArgKmin\n\u001b[0;32m     45\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_pairwise_fast\u001b[39;00m \u001b[39mimport\u001b[39;00m _chi2_kernel_fast, _sparse_manhattan\n\u001b[0;32m     48\u001b[0m \u001b[39m# Utility Functions\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\giorg\\OneDrive\\Desktop\\G\\Education\\Master\\Academics\\Courses\\15095 Machine Learning Under a Modern Optimization Lens\\Project\\TabText-Experiments\\MLVenv\\lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\__init__.py:89\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Pairwise Distances Reductions\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m# =============================\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[39m#    using Generalized Matrix Multiplication over `float64` data (see the\u001b[39;00m\n\u001b[0;32m     86\u001b[0m \u001b[39m#    docstring of :class:`GEMMTermComputer64` for details).\u001b[39;00m\n\u001b[1;32m---> 89\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_dispatcher\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     90\u001b[0m     ArgKmin,\n\u001b[0;32m     91\u001b[0m     ArgKminClassMode,\n\u001b[0;32m     92\u001b[0m     BaseDistancesReductionDispatcher,\n\u001b[0;32m     93\u001b[0m     RadiusNeighbors,\n\u001b[0;32m     94\u001b[0m     sqeuclidean_row_norms,\n\u001b[0;32m     95\u001b[0m )\n\u001b[0;32m     97\u001b[0m __all__ \u001b[39m=\u001b[39m [\n\u001b[0;32m     98\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mBaseDistancesReductionDispatcher\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     99\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mArgKmin\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39msqeuclidean_row_norms\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    103\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\giorg\\OneDrive\\Desktop\\G\\Education\\Master\\Academics\\Courses\\15095 Machine Learning Under a Modern Optimization Lens\\Project\\TabText-Experiments\\MLVenv\\lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py:9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m get_config\n\u001b[0;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_dist_metrics\u001b[39;00m \u001b[39mimport\u001b[39;00m BOOL_METRICS, METRIC_MAPPING64\n\u001b[1;32m----> 9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_argkmin\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     10\u001b[0m     ArgKmin32,\n\u001b[0;32m     11\u001b[0m     ArgKmin64,\n\u001b[0;32m     12\u001b[0m )\n\u001b[0;32m     13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_argkmin_classmode\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     14\u001b[0m     ArgKminClassMode32,\n\u001b[0;32m     15\u001b[0m     ArgKminClassMode64,\n\u001b[0;32m     16\u001b[0m )\n\u001b[0;32m     17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_base\u001b[39;00m \u001b[39mimport\u001b[39;00m _sqeuclidean_row_norms32, _sqeuclidean_row_norms64\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing _argkmin: The filename or extension is too long."
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, plot_confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "model = LogisticRegression(C=0.8,\n",
    "                           random_state=0,\n",
    "                           solver='lbfgs')\n",
    "model.fit(X_train, y_train)\n",
    "y_predict = model.predict(X_test)\n",
    "\n",
    "print('Accuracy Score is {:.5}'.format(accuracy_score(y_test, y_predict)))\n",
    "print(pd.DataFrame(confusion_matrix(y_test,y_predict)))\n",
    "\n",
    "sns.set_style('white') \n",
    "class_names = ['0','1']\n",
    "plot_confusion_matrix(confusion_matrix(y_test,y_predict),\n",
    "                      classes= class_names, normalize = True, \n",
    "                      title='Normalized Confusion Matrix: Logistic Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "DLL load failed while importing _argkmin: The filename or extension is too long.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\giorg\\OneDrive\\Desktop\\G\\Education\\Master\\Academics\\Courses\\15095 Machine Learning Under a Modern Optimization Lens\\Project\\TabText-Experiments\\Giorgio_baseline.ipynb Cell 68\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/giorg/OneDrive/Desktop/G/Education/Master/Academics/Courses/15095%20Machine%20Learning%20Under%20a%20Modern%20Optimization%20Lens/Project/TabText-Experiments/Giorgio_baseline.ipynb#Y304sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mmetrics\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\giorg\\OneDrive\\Desktop\\G\\Education\\Master\\Academics\\Courses\\15095 Machine Learning Under a Modern Optimization Lens\\Project\\TabText-Experiments\\MLVenv\\lib\\site-packages\\sklearn\\metrics\\__init__.py:7\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mThe :mod:`sklearn.metrics` module includes score functions, performance metrics\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39mand pairwise metrics and distance computations.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m cluster\n\u001b[0;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_classification\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m      9\u001b[0m     accuracy_score,\n\u001b[0;32m     10\u001b[0m     balanced_accuracy_score,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     27\u001b[0m     zero_one_loss,\n\u001b[0;32m     28\u001b[0m )\n\u001b[0;32m     29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_dist_metrics\u001b[39;00m \u001b[39mimport\u001b[39;00m DistanceMetric\n",
      "File \u001b[1;32mc:\\Users\\giorg\\OneDrive\\Desktop\\G\\Education\\Master\\Academics\\Courses\\15095 Machine Learning Under a Modern Optimization Lens\\Project\\TabText-Experiments\\MLVenv\\lib\\site-packages\\sklearn\\metrics\\cluster\\__init__.py:25\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_bicluster\u001b[39;00m \u001b[39mimport\u001b[39;00m consensus_score\n\u001b[0;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_supervised\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     10\u001b[0m     adjusted_mutual_info_score,\n\u001b[0;32m     11\u001b[0m     adjusted_rand_score,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     23\u001b[0m     v_measure_score,\n\u001b[0;32m     24\u001b[0m )\n\u001b[1;32m---> 25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_unsupervised\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     26\u001b[0m     calinski_harabasz_score,\n\u001b[0;32m     27\u001b[0m     davies_bouldin_score,\n\u001b[0;32m     28\u001b[0m     silhouette_samples,\n\u001b[0;32m     29\u001b[0m     silhouette_score,\n\u001b[0;32m     30\u001b[0m )\n\u001b[0;32m     32\u001b[0m __all__ \u001b[39m=\u001b[39m [\n\u001b[0;32m     33\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39madjusted_mutual_info_score\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     34\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mnormalized_mutual_info_score\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mconsensus_score\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     52\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\giorg\\OneDrive\\Desktop\\G\\Education\\Master\\Academics\\Courses\\15095 Machine Learning Under a Modern Optimization Lens\\Project\\TabText-Experiments\\MLVenv\\lib\\site-packages\\sklearn\\metrics\\cluster\\_unsupervised.py:22\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m _safe_indexing, check_random_state, check_X_y\n\u001b[0;32m     17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_param_validation\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     18\u001b[0m     Interval,\n\u001b[0;32m     19\u001b[0m     StrOptions,\n\u001b[0;32m     20\u001b[0m     validate_params,\n\u001b[0;32m     21\u001b[0m )\n\u001b[1;32m---> 22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpairwise\u001b[39;00m \u001b[39mimport\u001b[39;00m _VALID_METRICS, pairwise_distances, pairwise_distances_chunked\n\u001b[0;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcheck_number_of_labels\u001b[39m(n_labels, n_samples):\n\u001b[0;32m     26\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Check that number of labels are valid.\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \n\u001b[0;32m     28\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[39m        Number of samples.\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\giorg\\OneDrive\\Desktop\\G\\Education\\Master\\Academics\\Courses\\15095 Machine Learning Under a Modern Optimization Lens\\Project\\TabText-Experiments\\MLVenv\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:44\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mparallel\u001b[39;00m \u001b[39mimport\u001b[39;00m Parallel, delayed\n\u001b[0;32m     43\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mvalidation\u001b[39;00m \u001b[39mimport\u001b[39;00m _num_samples, check_non_negative\n\u001b[1;32m---> 44\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_pairwise_distances_reduction\u001b[39;00m \u001b[39mimport\u001b[39;00m ArgKmin\n\u001b[0;32m     45\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_pairwise_fast\u001b[39;00m \u001b[39mimport\u001b[39;00m _chi2_kernel_fast, _sparse_manhattan\n\u001b[0;32m     48\u001b[0m \u001b[39m# Utility Functions\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\giorg\\OneDrive\\Desktop\\G\\Education\\Master\\Academics\\Courses\\15095 Machine Learning Under a Modern Optimization Lens\\Project\\TabText-Experiments\\MLVenv\\lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\__init__.py:89\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Pairwise Distances Reductions\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m# =============================\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[39m#    using Generalized Matrix Multiplication over `float64` data (see the\u001b[39;00m\n\u001b[0;32m     86\u001b[0m \u001b[39m#    docstring of :class:`GEMMTermComputer64` for details).\u001b[39;00m\n\u001b[1;32m---> 89\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_dispatcher\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     90\u001b[0m     ArgKmin,\n\u001b[0;32m     91\u001b[0m     ArgKminClassMode,\n\u001b[0;32m     92\u001b[0m     BaseDistancesReductionDispatcher,\n\u001b[0;32m     93\u001b[0m     RadiusNeighbors,\n\u001b[0;32m     94\u001b[0m     sqeuclidean_row_norms,\n\u001b[0;32m     95\u001b[0m )\n\u001b[0;32m     97\u001b[0m __all__ \u001b[39m=\u001b[39m [\n\u001b[0;32m     98\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mBaseDistancesReductionDispatcher\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     99\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mArgKmin\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39msqeuclidean_row_norms\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    103\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\giorg\\OneDrive\\Desktop\\G\\Education\\Master\\Academics\\Courses\\15095 Machine Learning Under a Modern Optimization Lens\\Project\\TabText-Experiments\\MLVenv\\lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py:9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m get_config\n\u001b[0;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_dist_metrics\u001b[39;00m \u001b[39mimport\u001b[39;00m BOOL_METRICS, METRIC_MAPPING64\n\u001b[1;32m----> 9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_argkmin\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     10\u001b[0m     ArgKmin32,\n\u001b[0;32m     11\u001b[0m     ArgKmin64,\n\u001b[0;32m     12\u001b[0m )\n\u001b[0;32m     13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_argkmin_classmode\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     14\u001b[0m     ArgKminClassMode32,\n\u001b[0;32m     15\u001b[0m     ArgKminClassMode64,\n\u001b[0;32m     16\u001b[0m )\n\u001b[0;32m     17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_base\u001b[39;00m \u001b[39mimport\u001b[39;00m _sqeuclidean_row_norms32, _sqeuclidean_row_norms64\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing _argkmin: The filename or extension is too long."
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
