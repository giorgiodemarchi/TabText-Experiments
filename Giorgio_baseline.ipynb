{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1080,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1081,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/credit/application_record.csv')\n",
    "\n",
    "record = pd.read_csv('data/credit/credit_record.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1082,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (438557, 18)\n",
      "Index(['ID', 'CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY', 'CNT_CHILDREN',\n",
      "       'AMT_INCOME_TOTAL', 'NAME_INCOME_TYPE', 'NAME_EDUCATION_TYPE',\n",
      "       'NAME_FAMILY_STATUS', 'NAME_HOUSING_TYPE', 'DAYS_BIRTH',\n",
      "       'DAYS_EMPLOYED', 'FLAG_MOBIL', 'FLAG_WORK_PHONE', 'FLAG_PHONE',\n",
      "       'FLAG_EMAIL', 'OCCUPATION_TYPE', 'CNT_FAM_MEMBERS'],\n",
      "      dtype='object')\n",
      "Shape: (1048575, 3)\n",
      "Index(['ID', 'MONTHS_BALANCE', 'STATUS'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape: {data.shape}\")\n",
    "print(data.columns)\n",
    "print(f\"Shape: {record.shape}\")\n",
    "print(record.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaggle Notebook: https://www.kaggle.com/code/rikdifos/credit-card-approval-prediction-using-ml/notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1083,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45985"
      ]
     },
     "execution_count": 1083,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record.ID.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Target variable**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 0: 1-29 days past due \n",
    "- 1: 30-59 days past due \n",
    "- 2: 60-89 days overdue \n",
    "- 3: 90-119 days overdue \n",
    "- 4: 120-149 days overdue \n",
    "- 5: Overdue or bad debts, write-offs for more than 150 days \n",
    "- C: paid off that month \n",
    "- X: No loan for the month\n",
    "\n",
    "\n",
    "TARGET VARIABLE: User at risk (1/0). 1 if overdue for more than 60 days (label 2,3,4,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Approach 1**\n",
    "\n",
    "Bad Customer: A customer is classified as bad if they have:\n",
    "- More than 2 instances of a status between 1 and 4 (indicating being past due between 30 to 149 days) over their entire history, or\n",
    "- Any instance of a status of 5 (indicating overdue or bad debts for more than 150 days), or\n",
    "- A recent trend toward worsening status (e.g., moving from status 0 to 1 or higher in the last 6 months).\n",
    "\n",
    "Good Customer: A customer is considered good if none of the above conditions are met."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1079,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def is_worsening(status_list):\n",
    "#     for i in range(len(status_list) - 1):\n",
    "#         # Check if the status is worsening\n",
    "#         if status_list[i] < status_list[i + 1]:\n",
    "#             return True\n",
    "#     return False\n",
    "\n",
    "# record_d = pd.get_dummies(data=record,columns=['STATUS'], prefix='', prefix_sep='').groupby('ID')[sorted(record['STATUS'].unique().tolist())].sum()\n",
    "# record_d['bad_customer'] = np.where((record_d['1'] + record_d['2'] + record_d['3'] + record_d['4'] >= 2) | (record_d['5'] > 0), 1, 0)\n",
    "\n",
    "# record_past_6_monhts = record.groupby('ID').head(6)\n",
    "# record_past_6_monhts['STATUS'] = record_past_6_monhts['STATUS'].str.replace('C','-1')\n",
    "# record_past_6_monhts['STATUS'] = record_past_6_monhts['STATUS'].str.replace('X','-2')\n",
    "\n",
    "# # Group by Customer_ID and apply the function\n",
    "# worsening_customers = record_past_6_monhts.groupby('ID')['STATUS'].apply(list).apply(is_worsening)\n",
    "\n",
    "# worsening_customers_df = pd.DataFrame(worsening_customers).reset_index()\n",
    "# worsening_customers_df['STATUS'] = np.where(worsening_customers_df['STATUS'] == True, 1, 0)\n",
    "# worsening_customers_df.columns = ['ID','worsening']\n",
    "\n",
    "# new_record = pd.merge(record_d, worsening_customers_df, on='ID', how='left')[['ID','bad_customer','worsening']]\n",
    "# new_record['target'] = np.where(new_record['bad_customer'] == 1, 1, np.where(new_record['worsening'] == 1, 1, 0))\n",
    "# new_record = new_record.drop(['bad_customer','worsening'], axis=1)\n",
    "\n",
    "# new_data = pd.merge(data, record_d.reset_index()[['ID','bad_customer']], how='inner', on='ID')\n",
    "# new_data.rename(columns={'bad_customer':'target'}, inplace=True)\n",
    "# new_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Approach 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1084,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\giorg\\AppData\\Local\\Temp\\ipykernel_37044\\3319726218.py:2: FutureWarning: The provided callable <built-in function min> is currently using SeriesGroupBy.min. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"min\" instead.\n",
      "  begin_month = pd.DataFrame(record.groupby([\"ID\"])[\"MONTHS_BALANCE\"].agg(min))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    35841\n",
       "1      616\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 1084,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create variable \"begin_month\" --> age of the account\n",
    "begin_month = pd.DataFrame(record.groupby([\"ID\"])[\"MONTHS_BALANCE\"].agg(min))\n",
    "begin_month = begin_month.rename(columns={'MONTHS_BALANCE':'begin_month'}) \n",
    "\n",
    "new_data = pd.merge(data,begin_month,how=\"left\",on=\"ID\") #merge to record data\n",
    "\n",
    "\n",
    "record['dep_value'] = np.where(record['STATUS'].isin(['2','3','4','5']), 'Yes', None)\n",
    "\n",
    "# Flag customers who have been late 60+ days at least once\n",
    "cpunt = record.groupby('ID').count()\n",
    "cpunt['dep_value'] = np.where(cpunt['dep_value'] >0, 'Yes','No')\n",
    "cpunt = cpunt[['dep_value']]\n",
    "\n",
    "new_data = pd.merge(new_data, cpunt, how='inner', on='ID')\n",
    "\n",
    "new_data['target'] = new_data['dep_value']\n",
    "new_data['target'] = np.where(new_data['target']=='Yes', 1, 0)\n",
    "new_data = new_data.drop(columns=['dep_value','begin_month'])\n",
    "new_data.target.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binary Variables\n",
    "\n",
    "**Gender**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1085,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CODE_GENDER\n",
      "F    24430\n",
      "M    12027\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(new_data['CODE_GENDER'].value_counts())\n",
    "\n",
    "new_data['CODE_GENDER'] = np.where(new_data['CODE_GENDER']=='M', 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Own a car**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1086,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FLAG_OWN_CAR\n",
      "N    22614\n",
      "Y    13843\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(new_data['FLAG_OWN_CAR'].value_counts())\n",
    "\n",
    "new_data['FLAG_OWN_CAR'] = np.where(new_data['FLAG_OWN_CAR']=='Y', 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Own Realty**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1087,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FLAG_OWN_REALTY\n",
      "Y    24506\n",
      "N    11951\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(new_data['FLAG_OWN_REALTY'].value_counts())\n",
    "\n",
    "new_data['FLAG_OWN_REALTY'] = np.where(new_data['FLAG_OWN_REALTY']=='Y', 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Own Phone**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1088,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FLAG_PHONE\n",
      "0    25709\n",
      "1    10748\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(new_data['FLAG_PHONE'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Own Work Phone**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1089,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['FLAG_WORK_PHONE'] = np.where(new_data['FLAG_WORK_PHONE']=='Y', 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Own Email**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1090,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FLAG_EMAIL\n",
       "0    33186\n",
       "1     3271\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 1090,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data['FLAG_EMAIL'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numerical Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Children Count**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1091,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNT_CHILDREN\n",
       "0     25201\n",
       "1      7492\n",
       "2      3256\n",
       "3       419\n",
       "4        63\n",
       "5        20\n",
       "14        3\n",
       "7         2\n",
       "19        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 1091,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data['CNT_CHILDREN'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Income**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1092,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3.645700e+04\n",
       "mean     1.866857e+05\n",
       "std      1.017892e+05\n",
       "min      2.700000e+04\n",
       "25%      1.215000e+05\n",
       "50%      1.575000e+05\n",
       "75%      2.250000e+05\n",
       "max      1.575000e+06\n",
       "Name: AMT_INCOME_TOTAL, dtype: float64"
      ]
     },
     "execution_count": 1092,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data['AMT_INCOME_TOTAL'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1093,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['AMT_INCOME_TOTAL'] = new_data['AMT_INCOME_TOTAL']#/10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Age**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1094,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['AGE'] = new_data['DAYS_BIRTH']/-365\n",
    "\n",
    "new_data = new_data.drop(columns=['DAYS_BIRTH'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Working Years**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1095,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['YEARS_EMPLOYED'] = - new_data['DAYS_EMPLOYED'] / 365\t\n",
    "\n",
    "new_data = new_data.drop(columns=['DAYS_EMPLOYED'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Family Size**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1097,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNT_FAM_MEMBERS\n",
       "2.0     19463\n",
       "1.0      6987\n",
       "3.0      6421\n",
       "4.0      3106\n",
       "5.0       397\n",
       "6.0        58\n",
       "7.0        19\n",
       "15.0        3\n",
       "9.0         2\n",
       "20.0        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 1097,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data['CNT_FAM_MEMBERS'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical Variables\n",
    "\n",
    "**Occupation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1098,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the occupation categories\n",
    "laborwk_categories = ['Cleaning staff', 'Cooking staff', 'Drivers', 'Laborers', 'Low-skill Laborers', 'Security staff', 'Waiters/barmen staff']\n",
    "officewk_categories = ['Accountants', 'Core staff', 'HR staff', 'Medicine staff', 'Private service staff', 'Realty agents', 'Sales staff', 'Secretaries']\n",
    "hightecwk_categories = ['Managers', 'High skill tech staff', 'IT staff']\n",
    "\n",
    "new_data['OCCUPATION_TYPE'] = np.where(new_data['OCCUPATION_TYPE'].isin(laborwk_categories), 'labor', \n",
    "                                       np.where(new_data['OCCUPATION_TYPE'].isin(officewk_categories), 'office',\n",
    "                                                np.where(new_data['OCCUPATION_TYPE'].isin(hightecwk_categories), 'hightec', 'other')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1099,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OCCUPATION_TYPE\n",
       "other      11323\n",
       "labor      10496\n",
       "office     10183\n",
       "hightec     4455\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 1099,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.OCCUPATION_TYPE.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1100,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.get_dummies(new_data, columns=['OCCUPATION_TYPE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Income**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1101,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['NAME_INCOME_TYPE'] = np.where(new_data['NAME_INCOME_TYPE'].isin(['Pensioner', 'Student']), 'State servant' ,new_data['NAME_INCOME_TYPE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NAME_INCOME_TYPE\n",
       "Working                 18819\n",
       "State servant            9148\n",
       "Commercial associate     8490\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 1102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.NAME_INCOME_TYPE.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1103,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create dummy variables - one hot encoding\n",
    "new_data = pd.get_dummies(new_data, columns=['NAME_INCOME_TYPE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**House Type**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NAME_HOUSING_TYPE\n",
       "House / apartment      32548\n",
       "With parents            1776\n",
       "Municipal apartment     1128\n",
       "Rented apartment         575\n",
       "Office apartment         262\n",
       "Co-op apartment          168\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 1104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data['NAME_HOUSING_TYPE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1105,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.get_dummies(new_data, columns=['NAME_HOUSING_TYPE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Acedemic level**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NAME_EDUCATION_TYPE\n",
       "Secondary / secondary special    24777\n",
       "Higher education                  9864\n",
       "Incomplete higher                 1410\n",
       "Lower secondary                    374\n",
       "Academic degree                     32\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 1106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data['NAME_EDUCATION_TYPE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1107,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['NAME_EDUCATION_TYPE'] = np.where(new_data['NAME_EDUCATION_TYPE']=='Academic degree', 'Higher education', new_data['NAME_EDUCATION_TYPE'])\n",
    "\n",
    "# dummies\n",
    "new_data = pd.get_dummies(new_data, columns=['NAME_EDUCATION_TYPE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Marriage Condition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NAME_FAMILY_STATUS\n",
       "Married                 25048\n",
       "Single / not married     4829\n",
       "Civil marriage           2945\n",
       "Separated                2103\n",
       "Widow                    1532\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 1108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data['NAME_FAMILY_STATUS'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1109,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.get_dummies(new_data, columns=['NAME_FAMILY_STATUS'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1113,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = new_data.copy().drop(['ID'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1114,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, stratify=df['target'], test_size=0.3, random_state = 42)\n",
    "\n",
    "X_train, y_train = train_df.drop(['target'], axis=1), train_df['target']\n",
    "X_test, y_test = test_df.drop(['target'], axis=1), test_df['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SMOTE Oversampling on Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1115,
   "metadata": {},
   "outputs": [],
   "source": [
    "##SMOTE oversampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Apply SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_res, y_res = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    25088\n",
       "1    25088\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 1116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_res.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    10753\n",
       "1      185\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 1117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1119,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = ['AMT_INCOME_TOTAL','CNT_FAM_MEMBERS', 'AGE','YEARS_EMPLOYED','CNT_CHILDREN']\n",
    "X_train, y_train = X_res, y_res\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train[numerical_columns] = scaler.fit_transform(X_train[numerical_columns])\n",
    "\n",
    "X_test[numerical_columns] = scaler.transform(X_test[numerical_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CART**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10629</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>133</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1\n",
       "0  10629  124\n",
       "1    133   52"
      ]
     },
     "execution_count": 1121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_predict = model.predict(X_test)\n",
    "\n",
    "## METRICS\n",
    "# Accuracy\n",
    "cart_accuracy = accuracy_score(y_test, y_predict)\n",
    "\n",
    "# Precision\n",
    "cart_precision = precision_score(y_test, y_predict)\n",
    "\n",
    "# Recall\n",
    "cart_recall = recall_score(y_test, y_predict)\n",
    "\n",
    "# AUC\n",
    "cart_auc = roc_auc_score(y_test, y_predict)\n",
    "\n",
    "pd.DataFrame(confusion_matrix(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Decision Tree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.976504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.295455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.281081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC</th>\n",
       "      <td>0.634775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Decision Tree\n",
       "Accuracy        0.976504\n",
       "Precision       0.295455\n",
       "Recall          0.281081\n",
       "AUC             0.634775"
      ]
     },
     "execution_count": 1122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cart_metrics = pd.DataFrame({'Decision Tree': [cart_accuracy, cart_precision, cart_recall, cart_auc]}, columns = ['Decision Tree'], index=['Accuracy', 'Precision', 'Recall', 'AUC'])\n",
    "cart_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10667</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>142</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0   1\n",
       "0  10667  86\n",
       "1    142  43"
      ]
     },
     "execution_count": 1123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(class_weight ='balanced')  \n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf= rf.predict(X_test) \n",
    "\n",
    "## METRICS\n",
    "# Accuracy\n",
    "rf_accuracy = accuracy_score(y_test, y_pred_rf)\n",
    "\n",
    "# Precision\n",
    "rf_precision = precision_score(y_test, y_pred_rf)\n",
    "\n",
    "# Recall\n",
    "rf_recall = recall_score(y_test, y_pred_rf)\n",
    "\n",
    "# AUC\n",
    "rf_auc = roc_auc_score(y_test, y_pred_rf)\n",
    "\n",
    "pd.DataFrame(confusion_matrix(y_test,y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Random Forest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.979155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.232432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC</th>\n",
       "      <td>0.612217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Random Forest\n",
       "Accuracy        0.979155\n",
       "Precision       0.333333\n",
       "Recall          0.232432\n",
       "AUC             0.612217"
      ]
     },
     "execution_count": 1124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_metrics = pd.DataFrame({'Random Forest': [rf_accuracy, rf_precision, rf_recall, rf_auc]}, columns = ['Random Forest'], index=['Accuracy', 'Precision', 'Recall', 'AUC'])\n",
    "rf_metrics  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LightGBM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 25088, number of negative: 25088\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004725 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 50176, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10653</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>155</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1\n",
       "0  10653  100\n",
       "1    155   30"
      ]
     },
     "execution_count": 1127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LGBMClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_predict = model.predict(X_test)\n",
    "\n",
    "## METRICS\n",
    "# Accuracy\n",
    "lgm_accuracy = accuracy_score(y_test, y_predict)\n",
    "\n",
    "# Precision\n",
    "lgm_precision = precision_score(y_test, y_predict)\n",
    "\n",
    "# Recall\n",
    "lgm_recall = recall_score(y_test, y_predict)\n",
    "\n",
    "# AUC\n",
    "lgm_auc = roc_auc_score(y_test, y_predict)\n",
    "\n",
    "pd.DataFrame(confusion_matrix(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LightGBM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.976687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.230769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.162162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC</th>\n",
       "      <td>0.576431</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           LightGBM\n",
       "Accuracy   0.976687\n",
       "Precision  0.230769\n",
       "Recall     0.162162\n",
       "AUC        0.576431"
      ]
     },
     "execution_count": 1128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgm_metrics = pd.DataFrame({'LightGBM': [lgm_accuracy, lgm_precision, lgm_recall, lgm_auc]}, columns = ['LightGBM'], index=['Accuracy', 'Precision', 'Recall', 'AUC'])\n",
    "lgm_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**XGBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10651</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>146</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1\n",
       "0  10651  102\n",
       "1    146   39"
      ]
     },
     "execution_count": 1129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XGBClassifier()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_predict = model.predict(X_test)\n",
    "\n",
    "## METRICS\n",
    "# Accuracy\n",
    "xgb_accuracy = accuracy_score(y_test, y_predict)\n",
    "# Precision\n",
    "xgb_precision = precision_score(y_test, y_predict)\n",
    "# Recall\n",
    "xgb_recall = recall_score(y_test, y_predict)\n",
    "# AUC\n",
    "xgb_auc = roc_auc_score(y_test, y_predict)\n",
    "\n",
    "pd.DataFrame(confusion_matrix(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.977327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.276596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.210811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC</th>\n",
       "      <td>0.600663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            XGBoost\n",
       "Accuracy   0.977327\n",
       "Precision  0.276596\n",
       "Recall     0.210811\n",
       "AUC        0.600663"
      ]
     },
     "execution_count": 1130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_metrics = pd.DataFrame({'XGBoost': [xgb_accuracy, xgb_precision, xgb_recall, xgb_auc]}, columns = ['XGBoost'], index=['Accuracy', 'Precision', 'Recall', 'AUC'])\n",
    "xgb_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>LightGBM</th>\n",
       "      <th>XGBoost</th>\n",
       "      <th>Best Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.976504</td>\n",
       "      <td>0.979155</td>\n",
       "      <td>0.976687</td>\n",
       "      <td>0.977327</td>\n",
       "      <td>Random Forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.276596</td>\n",
       "      <td>Random Forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.281081</td>\n",
       "      <td>0.232432</td>\n",
       "      <td>0.162162</td>\n",
       "      <td>0.210811</td>\n",
       "      <td>Decision Tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC</th>\n",
       "      <td>0.634775</td>\n",
       "      <td>0.612217</td>\n",
       "      <td>0.576431</td>\n",
       "      <td>0.600663</td>\n",
       "      <td>Decision Tree</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Decision Tree  Random Forest  LightGBM   XGBoost     Best Model\n",
       "Accuracy        0.976504       0.979155  0.976687  0.977327  Random Forest\n",
       "Precision       0.295455       0.333333  0.230769  0.276596  Random Forest\n",
       "Recall          0.281081       0.232432  0.162162  0.210811  Decision Tree\n",
       "AUC             0.634775       0.612217  0.576431  0.600663  Decision Tree"
      ]
     },
     "execution_count": 1131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = pd.concat([cart_metrics, rf_metrics, lgm_metrics, xgb_metrics], axis=1)\n",
    "metrics['Best Model'] = metrics.idxmax(axis=1)\n",
    "metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
