{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/credit/application_record.csv')\n",
    "\n",
    "record = pd.read_csv('data/credit/credit_record.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (438557, 18)\n",
      "Index(['ID', 'CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY', 'CNT_CHILDREN',\n",
      "       'AMT_INCOME_TOTAL', 'NAME_INCOME_TYPE', 'NAME_EDUCATION_TYPE',\n",
      "       'NAME_FAMILY_STATUS', 'NAME_HOUSING_TYPE', 'DAYS_BIRTH',\n",
      "       'DAYS_EMPLOYED', 'FLAG_MOBIL', 'FLAG_WORK_PHONE', 'FLAG_PHONE',\n",
      "       'FLAG_EMAIL', 'OCCUPATION_TYPE', 'CNT_FAM_MEMBERS'],\n",
      "      dtype='object')\n",
      "Shape: (1048575, 3)\n",
      "Index(['ID', 'MONTHS_BALANCE', 'STATUS'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape: {data.shape}\")\n",
    "print(data.columns)\n",
    "print(f\"Shape: {record.shape}\")\n",
    "print(record.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaggle Notebook: https://www.kaggle.com/code/rikdifos/credit-card-approval-prediction-using-ml/notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Target variable**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 0: 1-29 days past due \n",
    "- 1: 30-59 days past due \n",
    "- 2: 60-89 days overdue \n",
    "- 3: 90-119 days overdue \n",
    "- 4: 120-149 days overdue \n",
    "- 5: Overdue or bad debts, write-offs for more than 150 days \n",
    "- C: paid off that month \n",
    "- X: No loan for the month\n",
    "\n",
    "\n",
    "TARGET VARIABLE: User at risk (1/0). 1 if overdue for more than 60 days (label 2,3,4,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STATUS\n",
       "C    442031\n",
       "0    383120\n",
       "X    209230\n",
       "1     11090\n",
       "5      1693\n",
       "2       868\n",
       "3       320\n",
       "4       223\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record.STATUS.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\giorg\\AppData\\Local\\Temp\\ipykernel_37044\\1215647021.py:2: FutureWarning: The provided callable <built-in function min> is currently using SeriesGroupBy.min. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"min\" instead.\n",
      "  begin_month = pd.DataFrame(record.groupby([\"ID\"])[\"MONTHS_BALANCE\"].agg(min))\n"
     ]
    }
   ],
   "source": [
    "# Create variable \"begin_month\" --> age of the account\n",
    "begin_month = pd.DataFrame(record.groupby([\"ID\"])[\"MONTHS_BALANCE\"].agg(min))\n",
    "begin_month = begin_month.rename(columns={'MONTHS_BALANCE':'begin_month'}) \n",
    "\n",
    "new_data = pd.merge(data,begin_month,how=\"left\",on=\"ID\") #merge to record data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    35841\n",
       "1      616\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record['dep_value'] = np.where(record['STATUS'].isin(['2','3','4','5']), 'Yes', None)\n",
    "\n",
    "# Flag customers who have been late 60+ days at least once\n",
    "cpunt = record.groupby('ID').count()\n",
    "cpunt['dep_value'] = np.where(cpunt['dep_value'] >0, 'Yes','No')\n",
    "cpunt = cpunt[['dep_value']]\n",
    "\n",
    "new_data = pd.merge(new_data, cpunt, how='inner', on='ID')\n",
    "\n",
    "new_data['target'] = new_data['dep_value']\n",
    "new_data['target'] = np.where(new_data['target']=='Yes', 1, 0)\n",
    "\n",
    "new_data.target.value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binary Variables\n",
    "\n",
    "**Gender**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CODE_GENDER\n",
      "F    24430\n",
      "M    12027\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(new_data['CODE_GENDER'].value_counts())\n",
    "\n",
    "new_data['CODE_GENDER'] = np.where(new_data['CODE_GENDER']=='M', 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data['CODE_GENDER'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Own a car**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FLAG_OWN_CAR\n",
      "N    22614\n",
      "Y    13843\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(new_data['FLAG_OWN_CAR'].value_counts())\n",
    "\n",
    "new_data['FLAG_OWN_CAR'] = np.where(new_data['FLAG_OWN_CAR']=='Y', 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Own Realty**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FLAG_OWN_REALTY\n",
      "Y    24506\n",
      "N    11951\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(new_data['FLAG_OWN_REALTY'].value_counts())\n",
    "\n",
    "new_data['FLAG_OWN_REALTY'] = np.where(new_data['FLAG_OWN_REALTY']=='Y', 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Own Phone**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FLAG_PHONE\n",
      "0    25709\n",
      "1    10748\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(new_data['FLAG_PHONE'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Own Work Phone**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['FLAG_WORK_PHONE'] = np.where(new_data['FLAG_WORK_PHONE']=='Y', 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Own Email**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FLAG_EMAIL\n",
       "0    33186\n",
       "1     3271\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data['FLAG_EMAIL'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numerical Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Children Count**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNT_CHILDREN\n",
       "0     25201\n",
       "1      7492\n",
       "2      3256\n",
       "3       419\n",
       "4        63\n",
       "5        20\n",
       "14        3\n",
       "7         2\n",
       "19        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data['CNT_CHILDREN'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNT_CHILDREN\n",
      "0               25201\n",
      "1                7492\n",
      "2+ childrens     3764\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "new_data['CNT_CHILDREN'] = np.where(new_data['CNT_CHILDREN']>=2, '2+ childrens',\n",
    "                                    np.where(new_data['CNT_CHILDREN']==1, '1', '0'))\n",
    "\n",
    "print(new_data['CNT_CHILDREN'].value_counts())\n",
    "new_data = pd.get_dummies(new_data, columns=['CNT_CHILDREN'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Income**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3.645700e+04\n",
       "mean     1.866857e+05\n",
       "std      1.017892e+05\n",
       "min      2.700000e+04\n",
       "25%      1.215000e+05\n",
       "50%      1.575000e+05\n",
       "75%      2.250000e+05\n",
       "max      1.575000e+06\n",
       "Name: AMT_INCOME_TOTAL, dtype: float64"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data['AMT_INCOME_TOTAL'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['AMT_INCOME_TOTAL'] = new_data['AMT_INCOME_TOTAL']#/10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AMT_INCOME_TOTAL\n",
       "low       14473\n",
       "high      11282\n",
       "medium    10702\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data['AMT_INCOME_TOTAL'] = pd.qcut(new_data['AMT_INCOME_TOTAL'], q = 3, labels = [\"low\",\"medium\", \"high\"])\n",
    "new_data['AMT_INCOME_TOTAL'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.get_dummies(new_data, columns=['AMT_INCOME_TOTAL'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Age**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['AGE'] = new_data['DAYS_BIRTH']/-365\n",
    "\n",
    "# new_data['AGE'] = pd.qcut(new_data['AGE'], q = 3, labels = [\"low\",\"medium\", \"high\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AGE\n",
       "34.728767    54\n",
       "42.517808    54\n",
       "46.290411    38\n",
       "40.183562    37\n",
       "41.479452    32\n",
       "             ..\n",
       "45.282192     1\n",
       "63.958904     1\n",
       "59.375342     1\n",
       "38.893151     1\n",
       "25.172603     1\n",
       "Name: count, Length: 7183, dtype: int64"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data['AGE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = new_data.drop(columns=['DAYS_BIRTH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.get_dummies(new_data, columns=['AGE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Working Years**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['YEARS_EMPLOYED'] = - new_data['DAYS_EMPLOYED'] / 365\t\n",
    "new_data['YEARS_EMPLOYED'] = np.where(new_data['YEARS_EMPLOYED']<0, np.nan,new_data['YEARS_EMPLOYED'])\n",
    "\n",
    "\n",
    "# new_data['YEARS_EMPLOYED'] = pd.qcut(new_data['YEARS_EMPLOYED'], q = 5, labels = [\"lowest\",\"low\",\"medium\",\"high\",\"highest\"])\n",
    "# new_data['YEARS_EMPLOYED'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['YEARS_EMPLOYED'] = new_data['YEARS_EMPLOYED'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.get_dummies(new_data, columns=['YEARS_EMPLOYED'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Family Size**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNT_FAM_MEMBERS\n",
       "2.0     19463\n",
       "1.0      6987\n",
       "3.0      6421\n",
       "4.0      3106\n",
       "5.0       397\n",
       "6.0        58\n",
       "7.0        19\n",
       "15.0        3\n",
       "9.0         2\n",
       "20.0        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data['CNT_FAM_MEMBERS'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['CNT_FAM_MEMBERS'] = np.where(new_data['CNT_FAM_MEMBERS']>=3, '3+ members', \n",
    "                                       np.where(new_data['CNT_FAM_MEMBERS']==2, '2',\n",
    "                                                np.where(new_data['CNT_FAM_MEMBERS']==1, '1', '0')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.get_dummies(new_data, columns=['CNT_FAM_MEMBERS'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical Variables\n",
    "\n",
    "**Occupation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the occupation categories\n",
    "laborwk_categories = ['Cleaning staff', 'Cooking staff', 'Drivers', 'Laborers', 'Low-skill Laborers', 'Security staff', 'Waiters/barmen staff']\n",
    "officewk_categories = ['Accountants', 'Core staff', 'HR staff', 'Medicine staff', 'Private service staff', 'Realty agents', 'Sales staff', 'Secretaries']\n",
    "hightecwk_categories = ['Managers', 'High skill tech staff', 'IT staff']\n",
    "\n",
    "new_data['OCCUPATION_TYPE'] = np.where(new_data['OCCUPATION_TYPE'].isin(laborwk_categories), 'labor', \n",
    "                                       np.where(new_data['OCCUPATION_TYPE'].isin(officewk_categories), 'office',\n",
    "                                                np.where(new_data['OCCUPATION_TYPE'].isin(hightecwk_categories), 'hightec', 'other')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OCCUPATION_TYPE\n",
       "other      11323\n",
       "labor      10496\n",
       "office     10183\n",
       "hightec     4455\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.OCCUPATION_TYPE.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.get_dummies(new_data, columns=['OCCUPATION_TYPE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Income**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['NAME_INCOME_TYPE'] = np.where(new_data['NAME_INCOME_TYPE'].isin(['Pensioner', 'Student']), 'State servant' ,new_data['NAME_INCOME_TYPE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NAME_INCOME_TYPE\n",
       "Working                 18819\n",
       "State servant            9148\n",
       "Commercial associate     8490\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.NAME_INCOME_TYPE.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create dummy variables - one hot encoding\n",
    "new_data = pd.get_dummies(new_data, columns=['NAME_INCOME_TYPE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**House Type**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NAME_HOUSING_TYPE\n",
       "House / apartment      32548\n",
       "With parents            1776\n",
       "Municipal apartment     1128\n",
       "Rented apartment         575\n",
       "Office apartment         262\n",
       "Co-op apartment          168\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data['NAME_HOUSING_TYPE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.get_dummies(new_data, columns=['NAME_HOUSING_TYPE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Acedemic level**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NAME_EDUCATION_TYPE\n",
       "Secondary / secondary special    24777\n",
       "Higher education                  9864\n",
       "Incomplete higher                 1410\n",
       "Lower secondary                    374\n",
       "Academic degree                     32\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data['NAME_EDUCATION_TYPE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['NAME_EDUCATION_TYPE'] = np.where(new_data['NAME_EDUCATION_TYPE']=='Academic degree', 'Higher education', new_data['NAME_EDUCATION_TYPE'])\n",
    "\n",
    "# dummies\n",
    "new_data = pd.get_dummies(new_data, columns=['NAME_EDUCATION_TYPE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Marriage Condition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NAME_FAMILY_STATUS\n",
       "Married                 25048\n",
       "Single / not married     4829\n",
       "Civil marriage           2945\n",
       "Separated                2103\n",
       "Widow                    1532\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data['NAME_FAMILY_STATUS'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.get_dummies(new_data, columns=['NAME_FAMILY_STATUS'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY', 'CNT_CHILDREN',\n",
       "       'AMT_INCOME_TOTAL', 'FLAG_MOBIL', 'FLAG_WORK_PHONE', 'FLAG_PHONE',\n",
       "       'FLAG_EMAIL', 'CNT_FAM_MEMBERS', 'begin_month', 'dep_value', 'target',\n",
       "       'AGE', 'YEARS_EMPLOYED', 'OCCUPATION_TYPE_hightec',\n",
       "       'OCCUPATION_TYPE_labor', 'OCCUPATION_TYPE_office',\n",
       "       'OCCUPATION_TYPE_other', 'NAME_INCOME_TYPE_Commercial associate',\n",
       "       'NAME_INCOME_TYPE_State servant', 'NAME_INCOME_TYPE_Working',\n",
       "       'NAME_HOUSING_TYPE_Co-op apartment',\n",
       "       'NAME_HOUSING_TYPE_House / apartment',\n",
       "       'NAME_HOUSING_TYPE_Municipal apartment',\n",
       "       'NAME_HOUSING_TYPE_Office apartment',\n",
       "       'NAME_HOUSING_TYPE_Rented apartment', 'NAME_HOUSING_TYPE_With parents',\n",
       "       'NAME_EDUCATION_TYPE_Higher education',\n",
       "       'NAME_EDUCATION_TYPE_Incomplete higher',\n",
       "       'NAME_EDUCATION_TYPE_Lower secondary',\n",
       "       'NAME_EDUCATION_TYPE_Secondary / secondary special',\n",
       "       'NAME_FAMILY_STATUS_Civil marriage', 'NAME_FAMILY_STATUS_Married',\n",
       "       'NAME_FAMILY_STATUS_Separated',\n",
       "       'NAME_FAMILY_STATUS_Single / not married', 'NAME_FAMILY_STATUS_Widow'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new_data.drop(['ID','target','dep_value'], axis=1)\n",
    "y = new_data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, \n",
    "                                                    stratify=y, test_size=0.3,\n",
    "                                                    random_state = 10086)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "##SMOTE oversampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Apply SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_res, y_res = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    25088\n",
       "1    25088\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_res.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    25088\n",
       "1      431\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = ['CNT_CHILDREN','AMT_INCOME_TOTAL','CNT_FAM_MEMBERS','begin_month', 'AGE', 'YEARS_EMPLOYED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_res[numerical_columns] = scaler.fit_transform(X_res[numerical_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY', 'CNT_CHILDREN',\n",
       "       'AMT_INCOME_TOTAL', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'FLAG_MOBIL',\n",
       "       'FLAG_WORK_PHONE', 'FLAG_PHONE', 'FLAG_EMAIL', 'CNT_FAM_MEMBERS',\n",
       "       'begin_month', 'AGE', 'YEARS_EMPLOYED', 'OCCUPATION_TYPE_hightec',\n",
       "       'OCCUPATION_TYPE_labor', 'OCCUPATION_TYPE_office',\n",
       "       'OCCUPATION_TYPE_other', 'NAME_INCOME_TYPE_Commercial associate',\n",
       "       'NAME_INCOME_TYPE_State servant', 'NAME_INCOME_TYPE_Working',\n",
       "       'NAME_HOUSING_TYPE_Co-op apartment',\n",
       "       'NAME_HOUSING_TYPE_House / apartment',\n",
       "       'NAME_HOUSING_TYPE_Municipal apartment',\n",
       "       'NAME_HOUSING_TYPE_Office apartment',\n",
       "       'NAME_HOUSING_TYPE_Rented apartment', 'NAME_HOUSING_TYPE_With parents',\n",
       "       'NAME_EDUCATION_TYPE_Higher education',\n",
       "       'NAME_EDUCATION_TYPE_Incomplete higher',\n",
       "       'NAME_EDUCATION_TYPE_Lower secondary',\n",
       "       'NAME_EDUCATION_TYPE_Secondary / secondary special',\n",
       "       'NAME_FAMILY_STATUS_Civil marriage', 'NAME_FAMILY_STATUS_Married',\n",
       "       'NAME_FAMILY_STATUS_Separated',\n",
       "       'NAME_FAMILY_STATUS_Single / not married', 'NAME_FAMILY_STATUS_Widow'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_res.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = X_res, y_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\giorg\\MIT\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\giorg\\MIT\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10753</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>185</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0  1\n",
       "0  10753  0\n",
       "1    185  0"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, auc, roc_curve, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "model = LogisticRegression(C=0.8,\n",
    "                           random_state=42,\n",
    "                           solver='lbfgs')\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "X_test[numerical_columns] = scaler.transform(X_test[numerical_columns])\n",
    "y_predict = model.predict(X_test)\n",
    "\n",
    "## METRICS\n",
    "# Accuracy\n",
    "log_accuracy = accuracy_score(y_test, y_predict)\n",
    "\n",
    "# Precision\n",
    "log_precision = precision_score(y_test, y_predict)\n",
    "\n",
    "# Recall\n",
    "log_recall = recall_score(y_test, y_predict)\n",
    "\n",
    "# AUC\n",
    "log_auc = roc_auc_score(y_test, y_predict)\n",
    "\n",
    "pd.DataFrame(confusion_matrix(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Logistic Regression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.983086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC</th>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Logistic Regression\n",
       "Accuracy              0.983086\n",
       "Precision             0.000000\n",
       "Recall                0.000000\n",
       "AUC                   0.500000"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Metrics dataframe\n",
    "log_metrics = pd.DataFrame({'Logistic Regression': [log_accuracy, log_precision, log_recall, log_auc]}, columns = ['Logistic Regression'], index=['Accuracy', 'Precision', 'Recall', 'AUC'])\n",
    "log_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CART**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7272</td>\n",
       "      <td>3481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>128</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1\n",
       "0  7272  3481\n",
       "1   128    57"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model = DecisionTreeClassifier(max_depth=12,\n",
    "                               min_samples_split=8,\n",
    "                               random_state=1024)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "X_test[numerical_columns] = scaler.transform(X_test[numerical_columns])\n",
    "y_predict = model.predict(X_test)\n",
    "\n",
    "\n",
    "## METRICS\n",
    "# Accuracy\n",
    "cart_accuracy = accuracy_score(y_test, y_predict)\n",
    "\n",
    "# Precision\n",
    "cart_precision = precision_score(y_test, y_predict)\n",
    "\n",
    "# Recall\n",
    "cart_recall = recall_score(y_test, y_predict)\n",
    "\n",
    "# AUC\n",
    "cart_auc = roc_auc_score(y_test, y_predict)\n",
    "\n",
    "pd.DataFrame(confusion_matrix(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Decision Tree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.670049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.016111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.308108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC</th>\n",
       "      <td>0.492192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Decision Tree\n",
       "Accuracy        0.670049\n",
       "Precision       0.016111\n",
       "Recall          0.308108\n",
       "AUC             0.492192"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cart_metrics = pd.DataFrame({'Decision Tree': [cart_accuracy, cart_precision, cart_recall, cart_auc]}, columns = ['Decision Tree'], index=['Accuracy', 'Precision', 'Recall', 'AUC'])\n",
    "cart_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\giorg\\MIT\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10753</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>185</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0  1\n",
       "0  10753  0\n",
       "1    185  0"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=250,\n",
    "                              max_depth=12,\n",
    "                              min_samples_leaf=16\n",
    "                              )\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "X_test[numerical_columns] = scaler.transform(X_test[numerical_columns])\n",
    "y_predict = model.predict(X_test)\n",
    "\n",
    "## METRICS\n",
    "# Accuracy\n",
    "rf_accuracy = accuracy_score(y_test, y_predict)\n",
    "\n",
    "# Precision\n",
    "rf_precision = precision_score(y_test, y_predict)\n",
    "\n",
    "# Recall\n",
    "rf_recall = recall_score(y_test, y_predict)\n",
    "\n",
    "# AUC\n",
    "rf_auc = roc_auc_score(y_test, y_predict)\n",
    "\n",
    "pd.DataFrame(confusion_matrix(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Random Forest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.983086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC</th>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Random Forest\n",
       "Accuracy        0.983086\n",
       "Precision       0.000000\n",
       "Recall          0.000000\n",
       "AUC             0.500000"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_metrics = pd.DataFrame({'Random Forest': [rf_accuracy, rf_precision, rf_recall, rf_auc]}, columns = ['Random Forest'], index=['Accuracy', 'Precision', 'Recall', 'AUC'])\n",
    "rf_metrics  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LightGBM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 25088, number of negative: 25088\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006072 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1337\n",
      "[LightGBM] [Info] Number of data points in the train set: 50176, number of used features: 33\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\giorg\\MIT\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10753</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>185</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0  1\n",
       "0  10753  0\n",
       "1    185  0"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "\n",
    "model = LGBMClassifier(num_leaves=31,\n",
    "                       max_depth=8, \n",
    "                       learning_rate=0.02,\n",
    "                       n_estimators=250,\n",
    "                       subsample = 0.8,\n",
    "                       colsample_bytree =0.8\n",
    "                      )\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "X_test[numerical_columns] = scaler.transform(X_test[numerical_columns])\n",
    "y_predict = model.predict(X_test)\n",
    "\n",
    "## METRICS\n",
    "# Accuracy\n",
    "lgm_accuracy = accuracy_score(y_test, y_predict)\n",
    "\n",
    "# Precision\n",
    "lgm_precision = precision_score(y_test, y_predict)\n",
    "\n",
    "# Recall\n",
    "lgm_recall = recall_score(y_test, y_predict)\n",
    "\n",
    "# AUC\n",
    "lgm_auc = roc_auc_score(y_test, y_predict)\n",
    "\n",
    "pd.DataFrame(confusion_matrix(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LightGBM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.983086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC</th>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           LightGBM\n",
       "Accuracy   0.983086\n",
       "Precision  0.000000\n",
       "Recall     0.000000\n",
       "AUC        0.500000"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgm_metrics = pd.DataFrame({'LightGBM': [lgm_accuracy, lgm_precision, lgm_recall, lgm_auc]}, columns = ['LightGBM'], index=['Accuracy', 'Precision', 'Recall', 'AUC'])\n",
    "lgm_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**XGBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10315</td>\n",
       "      <td>438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>176</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1\n",
       "0  10315  438\n",
       "1    176    9"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "model = XGBClassifier(max_depth=12,\n",
    "                      n_estimators=250,\n",
    "                      min_child_weight=8, \n",
    "                      subsample=0.8, \n",
    "                      learning_rate =0.02,    \n",
    "                      seed=42)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "X_test[numerical_columns] = scaler.transform(X_test[numerical_columns])\n",
    "y_predict = model.predict(X_test)\n",
    "\n",
    "## METRICS\n",
    "# Accuracy\n",
    "xgb_accuracy = accuracy_score(y_test, y_predict)\n",
    "# Precision\n",
    "xgb_precision = precision_score(y_test, y_predict)\n",
    "# Recall\n",
    "xgb_recall = recall_score(y_test, y_predict)\n",
    "# AUC\n",
    "xgb_auc = roc_auc_score(y_test, y_predict)\n",
    "\n",
    "pd.DataFrame(confusion_matrix(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.943865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.020134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.048649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC</th>\n",
       "      <td>0.503958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            XGBoost\n",
       "Accuracy   0.943865\n",
       "Precision  0.020134\n",
       "Recall     0.048649\n",
       "AUC        0.503958"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_metrics = pd.DataFrame({'XGBoost': [xgb_accuracy, xgb_precision, xgb_recall, xgb_auc]}, columns = ['XGBoost'], index=['Accuracy', 'Precision', 'Recall', 'AUC'])\n",
    "xgb_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>LightGBM</th>\n",
       "      <th>XGBoost</th>\n",
       "      <th>Best Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.983086</td>\n",
       "      <td>0.670049</td>\n",
       "      <td>0.983086</td>\n",
       "      <td>0.983086</td>\n",
       "      <td>0.943865</td>\n",
       "      <td>Logistic Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020134</td>\n",
       "      <td>XGBoost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.308108</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.048649</td>\n",
       "      <td>Decision Tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.492192</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.503958</td>\n",
       "      <td>XGBoost</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Logistic Regression  Decision Tree  Random Forest  LightGBM  \\\n",
       "Accuracy              0.983086       0.670049       0.983086  0.983086   \n",
       "Precision             0.000000       0.016111       0.000000  0.000000   \n",
       "Recall                0.000000       0.308108       0.000000  0.000000   \n",
       "AUC                   0.500000       0.492192       0.500000  0.500000   \n",
       "\n",
       "            XGBoost           Best Model  \n",
       "Accuracy   0.943865  Logistic Regression  \n",
       "Precision  0.020134              XGBoost  \n",
       "Recall     0.048649        Decision Tree  \n",
       "AUC        0.503958              XGBoost  "
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = pd.concat([log_metrics, cart_metrics, rf_metrics, lgm_metrics, xgb_metrics], axis=1)\n",
    "metrics['Best Model'] = metrics.idxmax(axis=1)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>LightGBM</th>\n",
       "      <th>XGBoost</th>\n",
       "      <th>Best Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.983086</td>\n",
       "      <td>0.670049</td>\n",
       "      <td>0.983086</td>\n",
       "      <td>0.983086</td>\n",
       "      <td>0.943865</td>\n",
       "      <td>Logistic Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020134</td>\n",
       "      <td>XGBoost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.308108</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.048649</td>\n",
       "      <td>Decision Tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.492192</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.503958</td>\n",
       "      <td>XGBoost</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Logistic Regression  Decision Tree  Random Forest  LightGBM  \\\n",
       "Accuracy              0.983086       0.670049       0.983086  0.983086   \n",
       "Precision             0.000000       0.016111       0.000000  0.000000   \n",
       "Recall                0.000000       0.308108       0.000000  0.000000   \n",
       "AUC                   0.500000       0.492192       0.500000  0.500000   \n",
       "\n",
       "            XGBoost           Best Model  \n",
       "Accuracy   0.943865  Logistic Regression  \n",
       "Precision  0.020134              XGBoost  \n",
       "Recall     0.048649        Decision Tree  \n",
       "AUC        0.503958              XGBoost  "
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
