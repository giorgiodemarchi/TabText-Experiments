{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Column(object):\n",
    "    \"\"\"\n",
    "    Column module containing functionality to convert feature values into written text\n",
    "\n",
    "    name: String corresponding to the name of the column in the data set.\n",
    "    attribute: String corresponging to the text description of the column.\n",
    "    col_type: The type of the column: binary, categorical or numerical.\n",
    "    verb: The verb required to conjugate the attribute.\n",
    "    encode_fn: The function used to encode categorical values of this column.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, name, attribute=None, col_type=None, verb=None, encode_fn=None):\n",
    "        self.name = name\n",
    "        self.attribute = attribute\n",
    "        self.type = col_type\n",
    "        self.verb = verb\n",
    "        self.encode_fn = encode_fn\n",
    "\n",
    "    def is_binary(self):\n",
    "        return self.type == \"binary\"\n",
    "\n",
    "    def is_categorical(self):\n",
    "        return self.type == \"categorical\"\n",
    "\n",
    "    def is_numerical(self):\n",
    "        return self.type == \"numerical\"\n",
    "\n",
    "    def create_sentence(self, value, imp_value, prefix, missing_word, replace_numbers, descriptive):\n",
    "        \"\"\"\n",
    "        Parameters::\n",
    "            value: The value of this column at a specific data point\n",
    "            imp_value: The imputed value of this column at a specific data point.\n",
    "            prefix: String containing the desired prefix to add at the beginning of the sentence (\"\", \"the Patient\", etc.)\n",
    "            missing_word: String describing how to handle missing values (e.g. \"\", \"is missing\" \"imp_replace\")\n",
    "            replace_numbers: Boolean indicating weather or not to replace numerical values with text (e.g. very low, high, normal)\n",
    "            descriptive: Boolean indicating weather or not the sentence should be descriptive.\n",
    "\n",
    "        Returns::\n",
    "            String with a sentence describing the column and its value.\n",
    "            In the case of missing values:\n",
    "                1. If missing_word == \"\" the sentence is the empty string\n",
    "                2. If missing_word == \"imp_replace\" the sentence is constructed using the imputed value\n",
    "                3. For all other cases the sentence is constructed using the text in the string missing_word\n",
    "\n",
    "        \"\"\"\n",
    "        if descriptive:\n",
    "            return self.create_descriptive_sentence(value, imp_value, prefix, missing_word, replace_numbers)\n",
    "        else:\n",
    "            return self.create_basic_sentence(value, imp_value, prefix, missing_word, replace_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Binary_Column(Column):\n",
    "    \"\"\"\n",
    "    Binary Column submodule for columns with values in [1, 0, true, false, \"1\", \"0\", \"true\", \"false\"]\n",
    "\n",
    "    verb: The positive from of the verb used to conjugate the attribute when value is 1, \"1\" or \"True\"\n",
    "    neg_verb: Negative form of the verb used to conjugate the attribute when value is 0, \"0\" or \"false\"\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, name, attribute, verb, neg_verb, encode_fn=None):\n",
    "        self.neg_verb = neg_verb\n",
    "        super().__init__(name, attribute, \"binary\", verb, encode_fn)\n",
    "\n",
    "\n",
    "    def create_descriptive_sentence(self, value, imp_value, prefix, missing_word, replace_numbers):\n",
    "        sentence = \"\"\n",
    "\n",
    "        if str(value).lower()  in [\"1\", \"0\", \"true\", \"false\"]:\n",
    "\n",
    "            if int(value) == 1:\n",
    "\n",
    "                sentence = prefix + \" \" + self.verb + \" \" + self.attribute\n",
    "\n",
    "            elif int(value) == 0:\n",
    "\n",
    "                sentence = prefix + \" \" + self.neg_verb + \" \" + self.attribute\n",
    "\n",
    "        return sentence\n",
    "\n",
    "\n",
    "    def create_basic_sentence(self, value, imp_value, prefix, missing_word, replace_numbers):\n",
    "\n",
    "        sentence = \"\"\n",
    "\n",
    "        if str(value).lower()  in [\"1\", \"0\", \"true\", \"false\"]:\n",
    "\n",
    "            if int(value) == 1:\n",
    "\n",
    "                sentence = self.verb + \" \" + self.attribute + \": yes\"\n",
    "\n",
    "            elif int(value) == 0:\n",
    "\n",
    "                sentence = self.neg_verb + \" \" + self.attribute +\" : no\"\n",
    "\n",
    "        elif missing_word != \"\":\n",
    "            sentence = self.verb + \" \" + self.attribute + \": \" + missing_word\n",
    "        return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Categorical_Column(Column):\n",
    "    \"\"\"\n",
    "    Categorical Column submodule for columns with non-numerical values\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, name, attribute, verb, encode_fn=None):\n",
    "        super().__init__(name, attribute, \"categorical\", verb, encode_fn)\n",
    "\n",
    "    def create_descriptive_sentence(self, value, imp_value, prefix, missing_word, replace_numbers):\n",
    "        if len(prefix) != 0:\n",
    "            prefix = prefix[:-1] + \"'s \"\n",
    "        sentence = \"\"\n",
    "        if str(value).lower() not in [\"nan\", \"\", \"none\", \"missing\"]:\n",
    "            sentence = prefix + self.attribute + \" \" + self.verb + \" \" + str(value)\n",
    "        elif missing_word not in [\"\", \"imp_replace\"]:\n",
    "            sentence = prefix  + self.attribute + \" \" + self.verb + \" \" + missing_word\n",
    "        elif missing_word == \"imp_replace\":\n",
    "            sentence = prefix + self.attribute + \" \" + self.verb + \" \" + str(imp_value)\n",
    "        return sentence\n",
    "\n",
    "\n",
    "    def create_basic_sentence(self, value, imp_value, missing_word, replace_numbers):\n",
    "        sentence = \"\"\n",
    "        if  str(value).lower() not in [\"nan\", \"\", \"none\", \"missing\"]:\n",
    "            sentence = self.attribute + \": \" + str(value)\n",
    "        elif missing_word not in [\"\", \"imp_replace\"]:\n",
    "            sentence = self.attribute + \": \" + missing_word\n",
    "        elif missing_word == \"imp_replace\":\n",
    "            sentence = self.attribute + \": \" + str(imp_value)\n",
    "        return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Numerical_Column(Column):\n",
    "    \"\"\"\n",
    "    Numerical Column submodule for columns with numerical values\n",
    "\n",
    "    avg: The average of the values observed for this column (to be computed usign Training set)\n",
    "    sd: The standard deviation of the values observed for this column (to be computed usign Training set)\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, name, attribute, verb, avg, sd, encode_fn = None):\n",
    "        self.avg = avg\n",
    "        self.sd = sd\n",
    "        super().__init__(name, attribute, \"numerical\", verb, encode_fn)\n",
    "\n",
    "\n",
    "    def create_descriptive_sentence(self, value, imp_value, prefix, missing_word, replace_numbers):\n",
    "        if len(prefix) != 0:\n",
    "            prefix = prefix[:-1] + \"'s \"\n",
    "        sentence = \"\"\n",
    "        if str(value).lower() not in [\"nan\", \"\", \"none\", \"missing\"]:\n",
    "            value = float(value)\n",
    "            col_value = self.encode_number(value, replace_numbers)\n",
    "            sentence = prefix  + self.attribute + \" \" + self.verb + \" \" + str(col_value)\n",
    "        elif  missing_word not in [\"\", \"imp_replace\"]:\n",
    "            sentence = prefix  + self.attribute + \" \" + self.verb + \" \" + missing_word\n",
    "        elif missing_word == \"imp_replace\":\n",
    "            col_value = self.encode_number(imp_value, replace_numbers)\n",
    "            sentence = prefix  + self.attribute + \" \" + self.verb + \" \" + str(col_value)\n",
    "        return sentence\n",
    "\n",
    "\n",
    "    def create_basic_sentence(self, value, imp_value, prefix, missing_word, replace_numbers):\n",
    "        sentence = \"\"\n",
    "        if  str(value).lower() not in [\"nan\", \"\", \"none\", \"missing\"]:\n",
    "            value = float(value)\n",
    "            col_value = self.encode_number(value, replace_numbers)\n",
    "            sentence = self.attribute + \": \" + str(col_value)\n",
    "        elif missing_word not in [\"\", \"imp_replace\"]:\n",
    "            sentence = self.attribute + \": \" + missing_word\n",
    "        elif missing_word == \"imp_replace\":\n",
    "            col_value = self.encode_number(imp_value, replace_numbers)\n",
    "            sentence = self.attribute + \": \" + str(col_value)\n",
    "        return sentence\n",
    "\n",
    "    def encode_number(self, value, replace_numbers):\n",
    "        new_value = value\n",
    "        if replace_numbers:\n",
    "            if self.avg - 2*self.sd > value:\n",
    "                new_value = \"very low\"\n",
    "            elif self.avg - 2*self.sd <= value < self.avg - self.sd:\n",
    "                new_value = \"low\"\n",
    "            elif self.avg + 2*self.sd >= value > self.avg + self.sd:\n",
    "                new_value = \"high\"\n",
    "            elif self.avg + 2*self.sd < value:\n",
    "                new_value = \"very high\"\n",
    "            else:\n",
    "                new_value = \"normal\"\n",
    "        return new_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Table(object):\n",
    "    \"\"\"\n",
    "    Table module containing tabular information for a specific id.\n",
    "\n",
    "    name: String corresponding to the name of the table.\n",
    "    df: Dataframe containing the tabular data for a specific id.\n",
    "    columns: List of Column objects corresponing to the columns in df.\n",
    "    metadata: String containing metadata information about this table structure.\n",
    "    time_col: Name of the column in df containing the timestamp for each observation.\n",
    "    imputer: Function used to impute the missing values in df.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, name=\"\", df=pd.DataFrame(), columns=None, metadata=None, imputer=None):\n",
    "\n",
    "        self.name = name\n",
    "        self.columns = columns\n",
    "        self.metadata = metadata\n",
    "        self.df = df\n",
    "        self.is_empty = pd.isna(df).all().all()\n",
    "\n",
    "    def create_encoded_imputed_vectors(self):\n",
    "        \"\"\"\n",
    "        Creates encoded and imputed versions of the table contents.\n",
    "        \"\"\"\n",
    "        encoded_df =  pd.DataFrame()\n",
    "\n",
    "        for column in self.columns:\n",
    "            col_values = self.df[column.name]\n",
    "            col_encoder = column.encode_fn\n",
    "            labels = col_encoder(col_values[col_values.notnull()])\n",
    "            encoded_df[column.name] = col_values\n",
    "            encoded_df[column.name] = pd.Series(labels, index=col_values[col_values.notnull()].index)\n",
    "\n",
    "        self.encodings = encoded_df\n",
    "\n",
    "\n",
    "    def create_text(self, prefix, missing_word, descriptive, meta, sep = \"</s>\"):\n",
    "        \"\"\"\n",
    "        Creates a timestamped dataframe; each row contains a String (paragraph) with all the tabular information for the\n",
    "        corresponding timestamp.\n",
    "\n",
    "        Paramteres::\n",
    "            prefix: String containing the desired prefix to add at the beginning of each sentence (\"\", \"the Patient\", etc.)\n",
    "            missing_word: String describing how to handle missing values (e.g. \"\", \"is missing\" \"imp_replace\")\n",
    "            replace_numbers: Boolean indicating weather or not to replace numerical values with text (e.g. very low, high, normal)\n",
    "            descriptive: Boolean indicating weather or not each sentence should be descriptive.\n",
    "            meta: Boolean indicating weather or not to include meta information in the paragraphs.\n",
    "            sep: String indicating what symbol to use at the end of the paragraph as a separator between tables.\n",
    "        \"\"\"\n",
    "        self.text = pd.DataFrame()\n",
    "        text = []\n",
    "\n",
    "        for t_i in range(self.df.shape[0]):\n",
    "\n",
    "            text_i = \"\"\n",
    "\n",
    "            if meta & (len(str(self.metadata)) >1):\n",
    "                text_i = self.metadata\n",
    "\n",
    "            for column in self.columns:\n",
    "\n",
    "                value = self.df.iloc[t_i][column.name]\n",
    "\n",
    "                imp_value = \"Unkwown\"\n",
    "                col_text = column.create_sentence(value, imp_value, prefix, missing_word, descriptive=descriptive, replace_numbers=True)\n",
    "\n",
    "                if len(col_text) >0:\n",
    "                    col_text += \", \"\n",
    "\n",
    "                text_i += col_text\n",
    "\n",
    "            text_i = text_i[:-2]+ \". \" + sep\n",
    "            text.append(text_i)\n",
    "\n",
    "        self.text[\"text\"] =  text\n",
    "\n",
    "    def create_embeddings(self):\n",
    "        \"\"\"\n",
    "        Creates a timestamped dataframe; each row contains NLP embeddings for the paragraph of the corresponding timestamp.\n",
    "        \"\"\"\n",
    "        embeddings = []\n",
    "\n",
    "        for i in range(self.text.shape[0]):\n",
    "\n",
    "            text = self.text.iloc[i][\"text\"]\n",
    "\n",
    "            full_embedding = get_biobert_embeddings(text)[0]\n",
    "\n",
    "            embeddings.append(full_embedding.reshape(-1))\n",
    "\n",
    "        emb_df =  pd.DataFrame(np.array(embeddings))\n",
    "        emb_df = emb_df.set_index(self.text.index)\n",
    "\n",
    "        merged_df = pd.concat([self.text, emb_df], axis=1)\n",
    "        merged_df = merged_df.rename({i: self.name + \"_\" + str(i) for i in range(len(embeddings[0]))}, axis='columns')\n",
    "\n",
    "        self.embeddings = merged_df.drop([\"text\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\giorg\\AppData\\Local\\Temp\\ipykernel_43444\\2114819241.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  train_df = pd.read_csv(\"data/census_income/adult_data\", sep=', ')\n",
      "C:\\Users\\giorg\\AppData\\Local\\Temp\\ipykernel_43444\\2114819241.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  test_df = pd.read_csv(\"data/census_income/adult.test\", sep=', ')\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"data/census_income/adult_data\", sep=', ')\n",
    "test_df = pd.read_csv(\"data/census_income/adult.test\", sep=', ')\n",
    "\n",
    "dataset = pd.concat([train_df, test_df])\n",
    "\n",
    "#NaN are flagged as \"?\"\n",
    "dataset['workclass'] = dataset['workclass'].replace('?', np.nan)\n",
    "dataset['occupation'] = dataset['occupation'].replace('?', np.nan)\n",
    "dataset['native.country'] = dataset['native.country'].replace('?', np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test: Categorical Column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "workclassColumn = Categorical_Column(name='workclass', attribute='Work Class', verb='is')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Th's Work Class is Unknown\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workclassColumn.create_descriptive_sentence(value=np.NaN, prefix=\"The\", missing_word=\"imp_replace\", imp_value=\"Unknown\", replace_numbers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Work Class: Unknown'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workclassColumn.create_basic_sentence(value=np.NaN, missing_word=\"imp_replace\", imp_value=\"Unknown\", replace_numbers=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test: Numerical Column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ageColumn = Numerical_Column(name='age', attribute='Age', verb='is', avg=dataset['age'].mean(), sd=dataset['age'].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Age: 39.0'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ageColumn.create_basic_sentence(value=dataset['age'].iloc[0], prefix=\"\", missing_word=\"imp_replace\", imp_value=dataset['age'].mean(), replace_numbers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Th's Age is 39.0\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ageColumn.create_descriptive_sentence(value=dataset['age'].iloc[0], prefix=\"The\", missing_word=\"imp_replace\", imp_value=dataset['age'].mean(), replace_numbers=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test: Binary Column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['sex_binary'] = np.where(dataset['sex']=='Male', 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sexColumn = Binary_Column(name='sex_binary', attribute='Male', verb='is', neg_verb='is not')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'is Male: yes'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sexColumn.create_basic_sentence(value=1, imp_value=\"\", prefix=\"The gender\", missing_word=\"imp_replace\", replace_numbers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The gender is Male'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sexColumn.create_descriptive_sentence(value=1, imp_value=\"\", prefix=\"The gender\", missing_word=\"imp_replace\", replace_numbers=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test on whole table**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "\n",
    "row = dataset.iloc[index]\n",
    "\n",
    "ageColumn = Numerical_Column(name='age', attribute='Age', verb='is', avg=dataset['age'].mean(), sd=dataset['age'].std())\n",
    "workclassColumn = Categorical_Column(name='workclass', attribute='Workclass', verb='is')\n",
    "educationColumn = Categorical_Column(name='education', attribute='Education', verb='is')\n",
    "education_numColumn = Numerical_Column(name='education.num', attribute='Education Number', verb='is', avg=dataset['education.num'].mean(), sd=dataset['education.num'].std())\n",
    "marital_statusColumn = Categorical_Column(name='marital.status', attribute='Marital Status', verb='is')\n",
    "occupationColumn = Categorical_Column(name='occupation', attribute='Occupation', verb='is')\n",
    "relationshipColumn = Categorical_Column(name='relationship', attribute='Relationship', verb='is')\n",
    "raceColumn = Categorical_Column(name='race', attribute=\"Race\", verb='is')\n",
    "sexColumn = Categorical_Column(name='sex', attribute=\"Gender\", verb='is')\n",
    "capital_gainColumn = Numerical_Column(name='capital.gain', attribute=\"Capital Gain\", verb='is', avg=dataset['capital.gain'].mean(), sd=dataset['capital.gain'].std())\n",
    "capital_lossColumn = Numerical_Column(name='capital.loss', attribute=\"Capital Loss\", verb='is', avg=dataset['capital.loss'].mean(), sd=dataset['capital.loss'].std())\n",
    "hours_per_weekColumn = Numerical_Column(name='hours.per.week', attribute=\"Hours per Week\", verb='is', avg=dataset['hours.per.week'].mean(), sd=dataset['hours.per.week'].std())\n",
    "native_countryColumn = Categorical_Column(name='native.country', attribute=\"Native Country\", verb='is')\n",
    "\n",
    "censusTable = Table(name=\"census\", \n",
    "                    df = dataset, \n",
    "                    columns=[ageColumn, workclassColumn, educationColumn, education_numColumn, \n",
    "                                                          marital_statusColumn, occupationColumn, relationshipColumn, raceColumn, \n",
    "                                                          sexColumn, capital_gainColumn, capital_lossColumn, hours_per_weekColumn, native_countryColumn], \n",
    "                    metadata=\"Census Income Dataset: \", \n",
    "                    imputer=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Census Income Dataset: The person's Age is nor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Census Income Dataset: The person's Age is nor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Census Income Dataset: The person's Age is nor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Census Income Dataset: The person's Age is hig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Census Income Dataset: The person's Age is nor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48837</th>\n",
       "      <td>Census Income Dataset: The person's Age is nor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48838</th>\n",
       "      <td>Census Income Dataset: The person's Age is hig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48839</th>\n",
       "      <td>Census Income Dataset: The person's Age is nor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48840</th>\n",
       "      <td>Census Income Dataset: The person's Age is nor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>Census Income Dataset: The person's Age is nor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48842 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text\n",
       "0      Census Income Dataset: The person's Age is nor...\n",
       "1      Census Income Dataset: The person's Age is nor...\n",
       "2      Census Income Dataset: The person's Age is nor...\n",
       "3      Census Income Dataset: The person's Age is hig...\n",
       "4      Census Income Dataset: The person's Age is nor...\n",
       "...                                                  ...\n",
       "48837  Census Income Dataset: The person's Age is nor...\n",
       "48838  Census Income Dataset: The person's Age is hig...\n",
       "48839  Census Income Dataset: The person's Age is nor...\n",
       "48840  Census Income Dataset: The person's Age is nor...\n",
       "48841  Census Income Dataset: The person's Age is nor...\n",
       "\n",
       "[48842 rows x 1 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "censusTable.create_text(prefix=\"The person \", missing_word=\"is missing\", descriptive=True, meta=True, sep=\"</s>\")\n",
    "censusTable.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "censusTable.text.to_csv('data/census_income/census_income_sentences.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Census Income Dataset: The person's Age is normal, The person's Workclass is State-gov, The person's Education is Bachelors, The person's Education Number is high, The person's Marital Status is Never-married, The person's Occupation is Adm-clerical, The person's Relationship is Not-in-family, The person's Race is White, The person's Gender is Male, The person's Capital Gain is normal, The person's Capital Loss is normal, The person's Hours per Week is normal, The person's Native Country is United-States. </s>\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_string = censusTable.text.iloc[0][\"text\"]\n",
    "first_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Model With Embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = pd.read_csv('data/embeddings.csv')\n",
    "\n",
    "features_df = dataset.reset_index().drop(columns=[\"index\"])\n",
    "\n",
    "dataset = features_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Engineering (same as in baseline)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify Numeric features\n",
    "numeric_features = ['age','fnlwgt','education.num','capital.gain','capital.loss','hours.per.week','income']\n",
    "cat_features = ['workclass','education','marital.status', 'occupation', 'relationship', 'race', 'sex', 'native.country']\n",
    "\n",
    "# Sex\n",
    "dataset[\"sex\"] = dataset[\"sex\"].map({\"Male\": 0, \"Female\":1})\n",
    "\n",
    "# Marital Status\n",
    "dataset[\"marital.status\"] = dataset[\"marital.status\"].replace(['Never-married','Divorced','Separated','Widowed'], 'Single')\n",
    "dataset[\"marital.status\"] = dataset[\"marital.status\"].replace(['Married-civ-spouse','Married-spouse-absent','Married-AF-spouse'], 'Married')\n",
    "dataset[\"marital.status\"] = dataset[\"marital.status\"].map({\"Married\":1, \"Single\":0})\n",
    "dataset[\"marital.status\"] = dataset[\"marital.status\"].astype(int)\n",
    "\n",
    "# Education\n",
    "dummies_ed = pd.get_dummies(dataset['education'], prefix='education')\n",
    "dataset = pd.concat([dataset, dummies_ed], axis=1)\n",
    "dataset = dataset.drop('education', axis=1)\n",
    "\n",
    "# Workclass\n",
    "dataset['workclass'] = dataset['workclass'].str.replace('?', 'Unemployed')   # Missing values\n",
    "dummies_w = pd.get_dummies(dataset['workclass'], prefix='workclass')\n",
    "dataset = pd.concat([dataset, dummies_w], axis=1)\n",
    "dataset = dataset.drop('workclass', axis=1)\n",
    "\n",
    "# Occupation\n",
    "dataset['occupation'] = dataset['occupation'].str.replace('?', 'Unemployed')   # Missing values\n",
    "dummies_o = pd.get_dummies(dataset['occupation'], prefix='occupation')\n",
    "dataset = pd.concat([dataset, dummies_o], axis=1)\n",
    "dataset = dataset.drop('occupation', axis=1)\n",
    "\n",
    "# Race \n",
    "dummies_r = pd.get_dummies(dataset['race'], prefix='race')\n",
    "dataset = pd.concat([dataset, dummies_r], axis=1)\n",
    "dataset = dataset.drop('race', axis=1)\n",
    "\n",
    "# Relationship\n",
    "dummies_re = pd.get_dummies(dataset['relationship'], prefix='relationship')\n",
    "dataset = pd.concat([dataset, dummies_re], axis=1)\n",
    "dataset = dataset.drop('relationship', axis=1)\n",
    "\n",
    "# Native Country and fnlwgt dropped\n",
    "dataset.drop(labels=[\"native.country\", \"fnlwgt\"], axis = 1, inplace = True)\n",
    "\n",
    "# Convert to bool\n",
    "for col in dataset.columns:\n",
    "    if dataset[col].dtype == 'bool':\n",
    "        dataset[col] = dataset[col].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['income']=dataset['income'].map({'<=50K': 0, '>50K': 1, '<=50K.': 0, '>50K.': 1}).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Without PCA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.concat([dataset, embeddings], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>income</th>\n",
       "      <th>sex_binary</th>\n",
       "      <th>education_10th</th>\n",
       "      <th>...</th>\n",
       "      <th>374</th>\n",
       "      <th>375</th>\n",
       "      <th>376</th>\n",
       "      <th>377</th>\n",
       "      <th>378</th>\n",
       "      <th>379</th>\n",
       "      <th>380</th>\n",
       "      <th>381</th>\n",
       "      <th>382</th>\n",
       "      <th>383</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001148</td>\n",
       "      <td>-0.017442</td>\n",
       "      <td>0.092456</td>\n",
       "      <td>0.095219</td>\n",
       "      <td>-0.013387</td>\n",
       "      <td>-0.073221</td>\n",
       "      <td>0.104762</td>\n",
       "      <td>0.014535</td>\n",
       "      <td>-0.044319</td>\n",
       "      <td>-0.010846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001280</td>\n",
       "      <td>-0.027532</td>\n",
       "      <td>0.084070</td>\n",
       "      <td>0.084152</td>\n",
       "      <td>-0.028333</td>\n",
       "      <td>-0.059644</td>\n",
       "      <td>0.091943</td>\n",
       "      <td>-0.007732</td>\n",
       "      <td>-0.037505</td>\n",
       "      <td>0.001786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015330</td>\n",
       "      <td>-0.007651</td>\n",
       "      <td>0.108652</td>\n",
       "      <td>0.079497</td>\n",
       "      <td>-0.003023</td>\n",
       "      <td>-0.079991</td>\n",
       "      <td>0.116133</td>\n",
       "      <td>0.019735</td>\n",
       "      <td>-0.052635</td>\n",
       "      <td>-0.002933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005265</td>\n",
       "      <td>-0.012854</td>\n",
       "      <td>0.091463</td>\n",
       "      <td>0.088137</td>\n",
       "      <td>-0.013124</td>\n",
       "      <td>-0.064002</td>\n",
       "      <td>0.116273</td>\n",
       "      <td>0.003250</td>\n",
       "      <td>-0.054972</td>\n",
       "      <td>0.005653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016198</td>\n",
       "      <td>-0.006476</td>\n",
       "      <td>0.122350</td>\n",
       "      <td>0.102755</td>\n",
       "      <td>0.000571</td>\n",
       "      <td>-0.081216</td>\n",
       "      <td>0.088777</td>\n",
       "      <td>0.001682</td>\n",
       "      <td>-0.048179</td>\n",
       "      <td>-0.010504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48837</th>\n",
       "      <td>39</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006846</td>\n",
       "      <td>-0.003409</td>\n",
       "      <td>0.089131</td>\n",
       "      <td>0.076167</td>\n",
       "      <td>-0.023011</td>\n",
       "      <td>-0.074823</td>\n",
       "      <td>0.100038</td>\n",
       "      <td>-0.001175</td>\n",
       "      <td>-0.049833</td>\n",
       "      <td>-0.001336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48838</th>\n",
       "      <td>64</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007624</td>\n",
       "      <td>-0.009914</td>\n",
       "      <td>0.084471</td>\n",
       "      <td>0.066098</td>\n",
       "      <td>-0.018355</td>\n",
       "      <td>-0.085555</td>\n",
       "      <td>0.133181</td>\n",
       "      <td>-0.014142</td>\n",
       "      <td>-0.067975</td>\n",
       "      <td>0.013283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48839</th>\n",
       "      <td>38</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014165</td>\n",
       "      <td>-0.006431</td>\n",
       "      <td>0.098493</td>\n",
       "      <td>0.085268</td>\n",
       "      <td>-0.014512</td>\n",
       "      <td>-0.074639</td>\n",
       "      <td>0.096582</td>\n",
       "      <td>0.011756</td>\n",
       "      <td>-0.050140</td>\n",
       "      <td>-0.006379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48840</th>\n",
       "      <td>44</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5455</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019287</td>\n",
       "      <td>-0.014969</td>\n",
       "      <td>0.098039</td>\n",
       "      <td>0.099007</td>\n",
       "      <td>-0.002364</td>\n",
       "      <td>-0.056246</td>\n",
       "      <td>0.102553</td>\n",
       "      <td>0.015269</td>\n",
       "      <td>-0.054333</td>\n",
       "      <td>-0.004718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>35</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003364</td>\n",
       "      <td>-0.028510</td>\n",
       "      <td>0.084225</td>\n",
       "      <td>0.079554</td>\n",
       "      <td>-0.023707</td>\n",
       "      <td>-0.060155</td>\n",
       "      <td>0.103005</td>\n",
       "      <td>-0.006111</td>\n",
       "      <td>-0.036461</td>\n",
       "      <td>0.004034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48842 rows × 443 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  education.num  marital.status  sex  capital.gain  capital.loss  \\\n",
       "0       39             13               0    0          2174             0   \n",
       "1       50             13               1    0             0             0   \n",
       "2       38              9               0    0             0             0   \n",
       "3       53              7               1    0             0             0   \n",
       "4       28             13               1    1             0             0   \n",
       "...    ...            ...             ...  ...           ...           ...   \n",
       "48837   39             13               0    1             0             0   \n",
       "48838   64              9               0    0             0             0   \n",
       "48839   38             13               1    0             0             0   \n",
       "48840   44             13               0    0          5455             0   \n",
       "48841   35             13               1    0             0             0   \n",
       "\n",
       "       hours.per.week  income  sex_binary  education_10th  ...       374  \\\n",
       "0                  40       0           1               0  ...  0.001148   \n",
       "1                  13       0           1               0  ... -0.001280   \n",
       "2                  40       0           1               0  ...  0.015330   \n",
       "3                  40       0           1               0  ...  0.005265   \n",
       "4                  40       0           0               0  ...  0.016198   \n",
       "...               ...     ...         ...             ...  ...       ...   \n",
       "48837              36       0           0               0  ...  0.006846   \n",
       "48838              40       0           1               0  ...  0.007624   \n",
       "48839              50       0           1               0  ...  0.014165   \n",
       "48840              40       0           1               0  ...  0.019287   \n",
       "48841              60       1           1               0  ...  0.003364   \n",
       "\n",
       "            375       376       377       378       379       380       381  \\\n",
       "0     -0.017442  0.092456  0.095219 -0.013387 -0.073221  0.104762  0.014535   \n",
       "1     -0.027532  0.084070  0.084152 -0.028333 -0.059644  0.091943 -0.007732   \n",
       "2     -0.007651  0.108652  0.079497 -0.003023 -0.079991  0.116133  0.019735   \n",
       "3     -0.012854  0.091463  0.088137 -0.013124 -0.064002  0.116273  0.003250   \n",
       "4     -0.006476  0.122350  0.102755  0.000571 -0.081216  0.088777  0.001682   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "48837 -0.003409  0.089131  0.076167 -0.023011 -0.074823  0.100038 -0.001175   \n",
       "48838 -0.009914  0.084471  0.066098 -0.018355 -0.085555  0.133181 -0.014142   \n",
       "48839 -0.006431  0.098493  0.085268 -0.014512 -0.074639  0.096582  0.011756   \n",
       "48840 -0.014969  0.098039  0.099007 -0.002364 -0.056246  0.102553  0.015269   \n",
       "48841 -0.028510  0.084225  0.079554 -0.023707 -0.060155  0.103005 -0.006111   \n",
       "\n",
       "            382       383  \n",
       "0     -0.044319 -0.010846  \n",
       "1     -0.037505  0.001786  \n",
       "2     -0.052635 -0.002933  \n",
       "3     -0.054972  0.005653  \n",
       "4     -0.048179 -0.010504  \n",
       "...         ...       ...  \n",
       "48837 -0.049833 -0.001336  \n",
       "48838 -0.067975  0.013283  \n",
       "48839 -0.050140 -0.006379  \n",
       "48840 -0.054333 -0.004718  \n",
       "48841 -0.036461  0.004034  \n",
       "\n",
       "[48842 rows x 443 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Models with no CV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score, r2_score\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\giorg\\MIT\\TabText-Experiments\\TabVenv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: accuracy 0.795467 - AUC 0.612250\n",
      "KNN: accuracy 0.806154 - AUC 0.602095\n",
      "CART: accuracy 0.783244 - AUC 0.705718\n",
      "NB: accuracy 0.831951 - AUC 0.768404\n",
      "RF: accuracy 0.815552 - AUC 0.710705\n",
      "XGB: accuracy 0.855599 - AUC 0.758203\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train = full_df.iloc[:32561].drop('income', axis=1), full_df.iloc[:32561]['income']\n",
    "X_test, Y_test = full_df.iloc[32561:].drop('income', axis=1), full_df.iloc[32561:]['income']\n",
    "\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('RF', RandomForestClassifier(n_estimators=100, max_features=3)))\n",
    "models.append(('XGB', XGBClassifier()))\n",
    "\n",
    "names = []\n",
    "accuracies = []\n",
    "aucs = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "\n",
    "for name, model in models:\n",
    "\n",
    "    model.fit(X_train, Y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    predictions = [round(value) for value in y_pred]\n",
    "\n",
    "    accuracy = accuracy_score(Y_test, predictions)\n",
    "    auc = roc_auc_score(Y_test, predictions)\n",
    "    precision = precision_score(Y_test, predictions)\n",
    "    recall = recall_score(Y_test, predictions)\n",
    "\n",
    "    names.append(name)\n",
    "    accuracies.append(accuracy)\n",
    "    aucs.append(auc)\n",
    "    precisions.append(precision_score(Y_test, predictions))\n",
    "    recalls.append(recall_score(Y_test, predictions))\n",
    "\n",
    "    msg = \"%s: accuracy %f - AUC %f\" % (name, accuracy, auc)\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Models with CV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    #(\"LR\", LogisticRegression()),\n",
    "    #(\"KNN\", KNeighborsClassifier()),\n",
    "    #(\"CART\", DecisionTreeClassifier()),\n",
    "    #(\"NB\", GaussianNB()),\n",
    "    #(\"RF\", RandomForestClassifier()),\n",
    "    (\"XGB\", XGBClassifier()),\n",
    "]\n",
    "\n",
    "param_grids = {\n",
    "\n",
    "    \"LogisticRegression\": {\n",
    "        \"C\": [0.01, 0.1, 1, 10, 100],\n",
    "        \"penalty\": [\"l1\", \"l2\"],\n",
    "        \"solver\": [\"liblinear\", \"saga\"],\n",
    "    },\n",
    "\n",
    "    \"KNeighborsClassifier\": {\n",
    "        \"n_neighbors\": [3, 5, 7, 9],\n",
    "        \"weights\": [\"uniform\", \"distance\"],\n",
    "        \"metric\": [\"euclidean\", \"manhattan\"],\n",
    "    },\n",
    "\n",
    "    \"DecisionTreeClassifier\": {\n",
    "        \"max_depth\": [3, 5, 10, None],\n",
    "        \"min_samples_split\": [2, 5, 10],\n",
    "        \"min_samples_leaf\": [1, 2, 4],\n",
    "    },\n",
    "\n",
    "    \"GaussianNB\": {\"var_smoothing\": [1e-9, 1e-8, 1e-7]},\n",
    "\n",
    "    \"RandomForestClassifier\": {\n",
    "        \"n_estimators\": [100, 200, 300],\n",
    "        \"max_features\": [2, 3, 4],\n",
    "        \"max_depth\": [None, 3, 5, 10],\n",
    "    },\n",
    "\n",
    "    \"XGBClassifier\": {\n",
    "        \"n_estimators\": [100, 200, 300],\n",
    "        \"learning_rate\": [0.01, 0.1, 0.2],\n",
    "        \"max_depth\": [3, 5, 7],\n",
    "    },\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running RandomizedSearchCV for XGBClassifier\n"
     ]
    }
   ],
   "source": [
    "#cell runs in 2min15\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "searches = {}\n",
    "SCORING_METRIC = \"roc_auc\"\n",
    "for name, model in models:\n",
    "    print(f\"Running RandomizedSearchCV for {model.__class__.__name__}\")\n",
    "    search = RandomizedSearchCV(\n",
    "        model,\n",
    "        param_grids[model.__class__.__name__],\n",
    "        cv=skf.split(X_train, Y_train),\n",
    "        scoring=SCORING_METRIC,\n",
    "        n_jobs=-1,\n",
    "        )\n",
    "    search.fit(X_train, Y_train)\n",
    "    searches[name] = search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_threshold(y_true, y_prob):\n",
    "    best_threshold = 0.5\n",
    "    best_score = 0\n",
    "    for threshold in np.arange(0.1, 0.9, 0.001):\n",
    "        score = f1_score(y_true, y_prob >= threshold)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_threshold = threshold\n",
    "    return best_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB: Best Threshold 0.40 - Accuracy 0.8625 - AUC 0.8115\n"
     ]
    }
   ],
   "source": [
    "# cell runs in 1min50\n",
    "names = []\n",
    "accuracies = []\n",
    "aucs = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "best_thresholds = []\n",
    "scores =[]\n",
    "r2s = []\n",
    "for name, search in searches.items():\n",
    "    model = search.best_estimator_\n",
    "    probas = model.predict_proba(X_train.values)[:, 1]\n",
    "    best_threshold = find_best_threshold(Y_train, probas) # for f1\n",
    "\n",
    "    # metrics on test set\n",
    "    preds = (model.predict_proba(X_test.values)[:, 1] >= best_threshold).astype(int)\n",
    "\n",
    "    auc = roc_auc_score(Y_test, preds)\n",
    "    accuracy = accuracy_score(Y_test, preds)\n",
    "    precision = precision_score(Y_test, preds)\n",
    "    recall = recall_score(Y_test, preds)\n",
    "    r2 = r2_score(Y_test, preds)\n",
    "\n",
    "    names.append(name)\n",
    "    aucs.append(auc)\n",
    "    accuracies.append(accuracy)\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    r2s.append(r2)\n",
    "    scores.append(search.best_score_)\n",
    "    best_thresholds.append(best_threshold)\n",
    "\n",
    "    msg = f\"{name}: Best Threshold {best_threshold:.2f} - Accuracy {accuracy:.4f} - AUC {auc:.4f}\"\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XGB</th>\n",
       "      <th>Best Value</th>\n",
       "      <th>Best Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.862478</td>\n",
       "      <td>0.862478</td>\n",
       "      <td>XGB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC</th>\n",
       "      <td>0.811466</td>\n",
       "      <td>0.811466</td>\n",
       "      <td>XGB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.706502</td>\n",
       "      <td>0.706502</td>\n",
       "      <td>XGB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.714769</td>\n",
       "      <td>0.714769</td>\n",
       "      <td>XGB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>0.237780</td>\n",
       "      <td>0.237780</td>\n",
       "      <td>XGB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Training score</th>\n",
       "      <td>0.921979</td>\n",
       "      <td>0.921979</td>\n",
       "      <td>XGB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     XGB  Best Value Best Model\n",
       "Accuracy        0.862478    0.862478        XGB\n",
       "AUC             0.811466    0.811466        XGB\n",
       "Precision       0.706502    0.706502        XGB\n",
       "Recall          0.714769    0.714769        XGB\n",
       "R2              0.237780    0.237780        XGB\n",
       "Training score  0.921979    0.921979        XGB"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = pd.DataFrame(\n",
    "    {\n",
    "        #\"Best threshold\": best_thresholds,\n",
    "        \"Accuracy\": accuracies,\n",
    "        \"AUC\": aucs,\n",
    "        \"Precision\": precisions,\n",
    "        \"Recall\": recalls,\n",
    "        \"R2\": r2s,\n",
    "        \"Training score\": scores,\n",
    "    },\n",
    "    index=names,\n",
    ").transpose()\n",
    "metrics[\"Best Value\"] = metrics.max(axis=1)\n",
    "metrics[\"Best Model\"] = metrics.idxmax(axis=1)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**With PCA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=3)\n",
    "embeddings_3d = pca.fit_transform(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_df = pd.DataFrame(embeddings_3d, columns=['x', 'y', 'z'])\n",
    "full_df_pca = pd.concat([embeddings_df, dataset], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\giorg\\MIT\\TabText-Experiments\\TabVenv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: accuracy 0.855906 - AUC 0.771873\n",
      "KNN: accuracy 0.827775 - AUC 0.740257\n",
      "CART: accuracy 0.767643 - AUC 0.698738\n",
      "NB: accuracy 0.580493 - AUC 0.702654\n",
      "RF: accuracy 0.837172 - AUC 0.742907\n",
      "XGB: accuracy 0.856274 - AUC 0.753078\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train = full_df_pca.iloc[:32561].drop('income', axis=1), full_df_pca.iloc[:32561]['income']\n",
    "X_test, Y_test = full_df_pca.iloc[32561:].drop('income', axis=1), full_df_pca.iloc[32561:]['income']\n",
    "\n",
    "numeric_features = ['age','education.num','capital.gain','capital.loss','hours.per.week', 'x', 'y', 'z']\n",
    "scaler = StandardScaler()\n",
    "X_train[numeric_features] = scaler.fit_transform(X_train[numeric_features])\n",
    "X_test[numeric_features] = scaler.transform(X_test[numeric_features])\n",
    "\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('RF', RandomForestClassifier(n_estimators=100, max_features=3)))\n",
    "models.append(('XGB', XGBClassifier()))\n",
    "\n",
    "names = []\n",
    "accuracies = []\n",
    "aucs = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "\n",
    "for name, model in models:\n",
    "\n",
    "    model.fit(X_train, Y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    predictions = [round(value) for value in y_pred]\n",
    "\n",
    "    accuracy = accuracy_score(Y_test, predictions)\n",
    "    auc = roc_auc_score(Y_test, predictions)\n",
    "    precision = precision_score(Y_test, predictions)\n",
    "    recall = recall_score(Y_test, predictions)\n",
    "\n",
    "    names.append(name)\n",
    "    accuracies.append(accuracy)\n",
    "    aucs.append(auc)\n",
    "    precisions.append(precision_score(Y_test, predictions))\n",
    "    recalls.append(recall_score(Y_test, predictions))\n",
    "\n",
    "    msg = \"%s: accuracy %f - AUC %f\" % (name, accuracy, auc)\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**With CV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    #(\"LR\", LogisticRegression()),\n",
    "    #(\"KNN\", KNeighborsClassifier()),\n",
    "    #(\"CART\", DecisionTreeClassifier()),\n",
    "    #(\"NB\", GaussianNB()),\n",
    "    #(\"RF\", RandomForestClassifier()),\n",
    "    (\"XGB\", XGBClassifier()),\n",
    "]\n",
    "\n",
    "param_grids = {\n",
    "\n",
    "    \"LogisticRegression\": {\n",
    "        \"C\": [0.01, 0.1, 1, 10, 100],\n",
    "        \"penalty\": [\"l1\", \"l2\"],\n",
    "        \"solver\": [\"liblinear\", \"saga\"],\n",
    "    },\n",
    "\n",
    "    \"KNeighborsClassifier\": {\n",
    "        \"n_neighbors\": [3, 5, 7, 9],\n",
    "        \"weights\": [\"uniform\", \"distance\"],\n",
    "        \"metric\": [\"euclidean\", \"manhattan\"],\n",
    "    },\n",
    "\n",
    "    \"DecisionTreeClassifier\": {\n",
    "        \"max_depth\": [3, 5, 10, None],\n",
    "        \"min_samples_split\": [2, 5, 10],\n",
    "        \"min_samples_leaf\": [1, 2, 4],\n",
    "    },\n",
    "\n",
    "    \"GaussianNB\": {\"var_smoothing\": [1e-9, 1e-8, 1e-7]},\n",
    "\n",
    "    \"RandomForestClassifier\": {\n",
    "        \"n_estimators\": [100, 200, 300],\n",
    "        \"max_features\": [2, 3, 4],\n",
    "        \"max_depth\": [None, 3, 5, 10],\n",
    "    },\n",
    "\n",
    "    \"XGBClassifier\": {\n",
    "        \"n_estimators\": [100, 200, 300],\n",
    "        \"learning_rate\": [0.01, 0.1, 0.2],\n",
    "        \"max_depth\": [3, 5, 7],\n",
    "    },\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running RandomizedSearchCV for XGBClassifier\n"
     ]
    }
   ],
   "source": [
    "#cell runs in 2min15\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "searches = {}\n",
    "SCORING_METRIC = \"roc_auc\"\n",
    "for name, model in models:\n",
    "    print(f\"Running RandomizedSearchCV for {model.__class__.__name__}\")\n",
    "    search = RandomizedSearchCV(\n",
    "        model,\n",
    "        param_grids[model.__class__.__name__],\n",
    "        cv=skf.split(X_train, Y_train),\n",
    "        scoring=SCORING_METRIC,\n",
    "        n_jobs=-1,\n",
    "        )\n",
    "    search.fit(X_train, Y_train)\n",
    "    searches[name] = search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_threshold(y_true, y_prob):\n",
    "    best_threshold = 0.5\n",
    "    best_score = 0\n",
    "    for threshold in np.arange(0.1, 0.9, 0.001):\n",
    "        score = f1_score(y_true, y_prob >= threshold)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_threshold = threshold\n",
    "    return best_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB: Best Threshold 0.37 - Accuracy 0.8640 - AUC 0.8219\n"
     ]
    }
   ],
   "source": [
    "# cell runs in 1min50\n",
    "names = []\n",
    "accuracies = []\n",
    "aucs = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "best_thresholds = []\n",
    "scores =[]\n",
    "r2s = []\n",
    "for name, search in searches.items():\n",
    "    model = search.best_estimator_\n",
    "    probas = model.predict_proba(X_train.values)[:, 1]\n",
    "    best_threshold = find_best_threshold(Y_train, probas) # for f1\n",
    "\n",
    "    # metrics on test set\n",
    "    preds = (model.predict_proba(X_test.values)[:, 1] >= best_threshold).astype(int)\n",
    "\n",
    "    auc = roc_auc_score(Y_test, preds)\n",
    "    accuracy = accuracy_score(Y_test, preds)\n",
    "    precision = precision_score(Y_test, preds)\n",
    "    recall = recall_score(Y_test, preds)\n",
    "    r2 = r2_score(Y_test, preds)\n",
    "\n",
    "    names.append(name)\n",
    "    aucs.append(auc)\n",
    "    accuracies.append(accuracy)\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    r2s.append(r2)\n",
    "    scores.append(search.best_score_)\n",
    "    best_thresholds.append(best_threshold)\n",
    "\n",
    "    msg = f\"{name}: Best Threshold {best_threshold:.2f} - Accuracy {accuracy:.4f} - AUC {auc:.4f}\"\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XGB</th>\n",
       "      <th>Best Value</th>\n",
       "      <th>Best Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.864013</td>\n",
       "      <td>0.864013</td>\n",
       "      <td>XGB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC</th>\n",
       "      <td>0.821899</td>\n",
       "      <td>0.821899</td>\n",
       "      <td>XGB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.700196</td>\n",
       "      <td>0.700196</td>\n",
       "      <td>XGB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.742070</td>\n",
       "      <td>0.742070</td>\n",
       "      <td>XGB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>0.246291</td>\n",
       "      <td>0.246291</td>\n",
       "      <td>XGB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Training score</th>\n",
       "      <td>0.925893</td>\n",
       "      <td>0.925893</td>\n",
       "      <td>XGB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     XGB  Best Value Best Model\n",
       "Accuracy        0.864013    0.864013        XGB\n",
       "AUC             0.821899    0.821899        XGB\n",
       "Precision       0.700196    0.700196        XGB\n",
       "Recall          0.742070    0.742070        XGB\n",
       "R2              0.246291    0.246291        XGB\n",
       "Training score  0.925893    0.925893        XGB"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = pd.DataFrame(\n",
    "    {\n",
    "        #\"Best threshold\": best_thresholds,\n",
    "        \"Accuracy\": accuracies,\n",
    "        \"AUC\": aucs,\n",
    "        \"Precision\": precisions,\n",
    "        \"Recall\": recalls,\n",
    "        \"R2\": r2s,\n",
    "        \"Training score\": scores,\n",
    "    },\n",
    "    index=names,\n",
    ").transpose()\n",
    "metrics[\"Best Value\"] = metrics.max(axis=1)\n",
    "metrics[\"Best Model\"] = metrics.idxmax(axis=1)\n",
    "metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
